
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Pendahuluan &#8212; My sample book</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'PraUas';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="KBinsDiscretizer" href="KBinsDiscretizer.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="My sample book - Home"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="My sample book - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Introducing
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="data_understanding.html"><strong>Data Understanding</strong></a></li>












<li class="toctree-l1"><a class="reference internal" href="outlier_detection.html">Outlier Detection</a></li>
<li class="toctree-l1"><a class="reference internal" href="naive_bays.html"><strong>Naive Bays</strong></a></li>

<li class="toctree-l1"><a class="reference internal" href="proyek.html">Proyek UTS Penambangan Data (A)</a></li>
<li class="toctree-l1"><a class="reference internal" href="clustering.html"><strong>Clustering</strong></a></li>





<li class="toctree-l1"><a class="reference internal" href="KBinsDiscretizer.html">KBinsDiscretizer</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#"><strong>Pendahuluan</strong></a></li>




















</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2FPraUas.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/PraUas.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Pendahuluan</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#"><strong>Pendahuluan</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#data-understanding"><strong>Data Understanding</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#integrasi-data"><strong>Integrasi Data</strong></a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mengambil-dan-menampilkan-dataset-wine-quality-dari-uci-dengan-ucimlrepo-dan-pandas">Mengambil dan Menampilkan Dataset Wine Quality dari UCI dengan ucimlrepo dan pandas</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fitur-x-dan-target-y-digabung">Fitur X dan target y digabung</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#penjelasan-setiap-fitur-variabel-dataset-anggur"><strong>Penjelasan Setiap Fitur (Variabel) Dataset Anggur</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#variabel-target-output">Variabel Target (Output):</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#eksplorasi-data"><strong>Eksplorasi Data</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visualisasi-data"><strong>Visualisasi Data</strong></a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#preprocessing-data"><strong>Preprocessing Data</strong></a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rumus-untuk-standardisasi-standardscaler">1. Rumus untuk Standardisasi (StandardScaler)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rumus-untuk-reduksi-dimensi-pca-principal-component-analysis">2. Rumus untuk Reduksi Dimensi (PCA - Principal Component Analysis)</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#deteksi-outlier-menggunakan-local-outlier-factor-lof"><strong>deteksi outlier menggunakan Local Outlier Factor (LOF)</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#menggunakan-local-outlier-factor-lof-untuk-mendeteksi-outlier-pada-data-anggur-dan-ingin-memahami-konsep-konsep-di-baliknya-secara-berurutan-ini-adalah-pilihan-yang-sangat-baik-karena-lof-adalah-metode-yang-kuat-untuk-mendeteksi-outlier-berbasis-kepadatan">menggunakan <strong>Local Outlier Factor (LOF)</strong> untuk mendeteksi <em>outlier</em> pada data anggur, dan ingin memahami konsep-konsep di baliknya secara berurutan. Ini adalah pilihan yang sangat baik karena LOF adalah metode yang kuat untuk mendeteksi <em>outlier</em> berbasis kepadatan.</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#konsep-lof">Konsep LOF</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#k-distance-dan-k-neighbors">1. K-distance dan K-neighbors</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#reachability-distance-rd">2. Reachability Distance (RD)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#local-reachability-density-lrd">3. Local Reachability Density (LRD)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#local-outlier-factor-lof">4. Local Outlier Factor (LOF)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#pengecekan-ulang-apakah-data-masih-memiliki-outlier"><strong>pengecekan ulang apakah data masih memiliki outlier</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#menghapus-outlier-dengan-iqr"><strong>Menghapus Outlier dengan IQR</strong></a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rumus-matematika-deteksi-outlier-dengan-metode-iqr">Rumus Matematika Deteksi Outlier dengan Metode IQR</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#data-splitting"><strong>Data Splitting</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#klasifikasi-dengan-k-nearest-neighbors-knn"><strong>Klasifikasi dengan K-Nearest Neighbors (KNN)</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#tujuan-knn">🧭 <strong>Tujuan KNN:</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#langkah-langkah-knn-manual-dengan-jarak-euclidean">✅ <strong>Langkah-Langkah KNN (Manual dengan Jarak Euclidean)</strong></a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#langkah-1-hitung-jarak-euclidean-antara-data-uji-dan-semua-data-latih"><strong>Langkah 1: Hitung Jarak Euclidean antara data uji dan semua data latih</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#langkah-2-urutkan-data-latih-berdasarkan-jarak-terkecil"><strong>Langkah 2: Urutkan data latih berdasarkan jarak terkecil</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#langkah-3-ambil-k-tetangga-terdekat"><strong>Langkah 3: Ambil k tetangga terdekat</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#langkah-4-lakukan-voting-mayoritas-dari-label-k-tetangga"><strong>Langkah 4: Lakukan voting mayoritas dari label k tetangga</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#langkah-5-prediksi-selesai"><strong>Langkah 5: Prediksi selesai</strong></a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#klasifikasi-dengan-naive-bayes-gaussiannb"><strong>Klasifikasi dengan Naive Bayes (GaussianNB)</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#naive-bayes-classifier">📘 <strong>Naive Bayes Classifier</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#langkah-langkah-rumus-naive-bayes">✅ <strong>Langkah-langkah &amp; Rumus Naive Bayes</strong></a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#langkah-1-hitung-probabilitas-prior-tiap-kelas">🔹 <strong>Langkah 1: Hitung Probabilitas Prior Tiap Kelas</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#langkah-2-hitung-probabilitas-likelihood-untuk-tiap-fitur">🔹 <strong>Langkah 2: Hitung Probabilitas Likelihood untuk Tiap Fitur</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#untuk-data-numerik-gaussian-naive-bayes-digunakan-distribusi-normal">Untuk data numerik (Gaussian Naive Bayes), digunakan distribusi normal:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#untuk-data-kategorikal-multinomial-bernoulli-naive-bayes">Untuk data kategorikal (Multinomial/ Bernoulli Naive Bayes):</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#langkah-3-gunakan-teorema-bayes-untuk-probabilitas-posterior">🔹 <strong>Langkah 3: Gunakan Teorema Bayes untuk Probabilitas Posterior</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#langkah-4-pilih-kelas-dengan-probabilitas-posterior-tertinggi">🔹 <strong>Langkah 4: Pilih Kelas dengan Probabilitas Posterior Tertinggi</strong></a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#ringkasan-singkat">🔁 Ringkasan Singkat:</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#klasifikasi-dengan-decision-tree"><strong>Klasifikasi dengan Decision Tree</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#decision-tree">🌳 <strong>4. Decision Tree</strong></a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#langkah-langkah-decision-tree">✅ <strong>Langkah-langkah Decision Tree</strong></a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#rumus-rumus-penting">🧠 Rumus-Rumus Penting</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#entropy">🔹 1. <strong>Entropy</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gini-impurity">🔹 2. <strong>Gini Impurity</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#information-gain-ig">🔹 3. <strong>Information Gain (IG)</strong></a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#ringkasan-langkah-recursive-decision-tree">🧭 Ringkasan Langkah Recursive Decision Tree</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluasi-model"><strong>Evaluasi Model</strong></a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#penerapan-ke-knn"><strong>Penerapan ke KNN</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#penerapan-ke-naive-bayes"><strong>Penerapan ke Naive Bayes</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#penerapan-ke-decision-tree"><strong>Penerapan ke Decision Tree</strong></a></li>
</ul>
</li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <p>#<strong>Klasifikasi Varietas Berdasarkan Analisis Kimia</strong></p>
<section id="pendahuluan">
<h1><strong>Pendahuluan</strong><a class="headerlink" href="#pendahuluan" title="Link to this heading">#</a></h1>
<p>Dalam dunia analisis data dan pembelajaran mesin, memahami data adalah langkah fundamental sebelum memulai proyek apa pun. Dataset Anggur (Wine Dataset) dari UCI Machine Learning Repository adalah contoh klasik yang sangat populer untuk tujuan edukasi dan penelitian. Dataset ini menawarkan studi kasus yang menarik tentang bagaimana karakteristik kimia dapat digunakan untuk mengidentifikasi dan mengklasifikasikan jenis suatu produk.</p>
</section>
<section id="data-understanding">
<h1><strong>Data Understanding</strong><a class="headerlink" href="#data-understanding" title="Link to this heading">#</a></h1>
</section>
<section id="integrasi-data">
<h1><strong>Integrasi Data</strong><a class="headerlink" href="#integrasi-data" title="Link to this heading">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>ucimlrepo
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: ucimlrepo in c:\python313\lib\site-packages (0.0.7)
Requirement already satisfied: pandas&gt;=1.0.0 in c:\python313\lib\site-packages (from ucimlrepo) (2.3.0)
Requirement already satisfied: certifi&gt;=2020.12.5 in c:\python313\lib\site-packages (from ucimlrepo) (2025.6.15)
Requirement already satisfied: numpy&gt;=1.26.0 in c:\python313\lib\site-packages (from pandas&gt;=1.0.0-&gt;ucimlrepo) (2.3.0)
Requirement already satisfied: python-dateutil&gt;=2.8.2 in c:\python313\lib\site-packages (from pandas&gt;=1.0.0-&gt;ucimlrepo) (2.9.0.post0)
Requirement already satisfied: pytz&gt;=2020.1 in c:\python313\lib\site-packages (from pandas&gt;=1.0.0-&gt;ucimlrepo) (2025.2)
Requirement already satisfied: tzdata&gt;=2022.7 in c:\python313\lib\site-packages (from pandas&gt;=1.0.0-&gt;ucimlrepo) (2025.2)
Requirement already satisfied: six&gt;=1.5 in c:\python313\lib\site-packages (from python-dateutil&gt;=2.8.2-&gt;pandas&gt;=1.0.0-&gt;ucimlrepo) (1.17.0)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[notice] A new release of pip is available: 25.0.1 -&gt; 25.1.1
[notice] To update, run: python.exe -m pip install --upgrade pip
</pre></div>
</div>
</div>
</div>
<section id="mengambil-dan-menampilkan-dataset-wine-quality-dari-uci-dengan-ucimlrepo-dan-pandas">
<h2>Mengambil dan Menampilkan Dataset Wine Quality dari UCI dengan ucimlrepo dan pandas<a class="headerlink" href="#mengambil-dan-menampilkan-dataset-wine-quality-dari-uci-dengan-ucimlrepo-dan-pandas" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ucimlrepo</span><span class="w"> </span><span class="kn">import</span> <span class="n">fetch_ucirepo</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="c1"># Mengambil dataset Wine Quality (ID: 109)</span>
<span class="n">wine</span> <span class="o">=</span> <span class="n">fetch_ucirepo</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="mi">109</span><span class="p">)</span>

<span class="c1"># Menyimpan fitur dan target ke DataFrame</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">wine</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">features</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">wine</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">targets</span>

<span class="c1"># Menampilkan beberapa baris awal data</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Fitur (X):&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Target (y):&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>

<span class="c1"># Menampilkan metadata dataset</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Metadata Dataset:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">wine</span><span class="o">.</span><span class="n">metadata</span><span class="p">)</span>

<span class="c1"># Menampilkan informasi variabel</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Informasi Variabel:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">wine</span><span class="o">.</span><span class="n">variables</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ModuleNotFoundError</span><span class="g g-Whitespace">                       </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">line</span> <span class="mi">1</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="kn">from</span><span class="w"> </span><span class="nn">ucimlrepo</span><span class="w"> </span><span class="kn">import</span> <span class="n">fetch_ucirepo</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span> <span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span> <span class="c1"># Mengambil dataset Wine Quality (ID: 109)</span>

<span class="ne">ModuleNotFoundError</span>: No module named &#39;ucimlrepo&#39;
</pre></div>
</div>
</div>
</div>
</section>
<section id="fitur-x-dan-target-y-digabung">
<h2>Fitur X dan target y digabung<a class="headerlink" href="#fitur-x-dan-target-y-digabung" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ucimlrepo</span><span class="w"> </span><span class="kn">import</span> <span class="n">fetch_ucirepo</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="c1"># Mengatur opsi tampilan Pandas agar semua kolom ditampilkan tanpa terpotong</span>
<span class="c1"># pd.set_option(&#39;display.max_columns&#39;, None) akan menampilkan semua kolom</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.max_columns&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
<span class="c1"># pd.set_option(&#39;display.width&#39;, None) mungkin juga membantu jika lebar terminal/konsol sangat kecil</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.width&#39;</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span> <span class="c1"># Atur lebar tampilan agar cukup luas</span>

<span class="c1"># Mengambil dataset Wine (ID: 109)</span>
<span class="n">wine</span> <span class="o">=</span> <span class="n">fetch_ucirepo</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="mi">109</span><span class="p">)</span>

<span class="c1"># Menyimpan fitur ke DataFrame X</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">wine</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">features</span>

<span class="c1"># Menyimpan target ke DataFrame y</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">wine</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">targets</span>

<span class="c1"># Menggabungkan X dan y menjadi satu DataFrame</span>
<span class="n">full_dataset</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Menampilkan 5 baris pertama dari dataset gabungan</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Tampilan Dataset Lengkap (Fitur X dan Target y Digabung):&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">full_dataset</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>

<span class="c1"># Mengembalikan opsi tampilan Pandas ke default (opsional, tapi disarankan setelah selesai)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">reset_option</span><span class="p">(</span><span class="s1">&#39;display.max_columns&#39;</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">reset_option</span><span class="p">(</span><span class="s1">&#39;display.width&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Tampilan Dataset Lengkap (Fitur X dan Target y Digabung):
   Alcohol  Malicacid   Ash  Alcalinity_of_ash  Magnesium  Total_phenols  Flavanoids  Nonflavanoid_phenols  Proanthocyanins  Color_intensity   Hue  0D280_0D315_of_diluted_wines  Proline  class
0    14.23       1.71  2.43               15.6        127           2.80        3.06                  0.28             2.29             5.64  1.04                          3.92     1065      1
1    13.20       1.78  2.14               11.2        100           2.65        2.76                  0.26             1.28             4.38  1.05                          3.40     1050      1
2    13.16       2.36  2.67               18.6        101           2.80        3.24                  0.30             2.81             5.68  1.03                          3.17     1185      1
3    14.37       1.95  2.50               16.8        113           3.85        3.49                  0.24             2.18             7.80  0.86                          3.45     1480      1
4    13.24       2.59  2.87               21.0        118           2.80        2.69                  0.39             1.82             4.32  1.04                          2.93      735      1
</pre></div>
</div>
</div>
</div>
<p>Dataset ini berisi 13 fitur kimia, dan satu variabel target (<code class="docutils literal notranslate"><span class="pre">class</span></code>). Berikut adalah penjelasan untuk masing-masing:</p>
</section>
<hr class="docutils" />
<section id="penjelasan-setiap-fitur-variabel-dataset-anggur">
<h2><strong>Penjelasan Setiap Fitur (Variabel) Dataset Anggur</strong><a class="headerlink" href="#penjelasan-setiap-fitur-variabel-dataset-anggur" title="Link to this heading">#</a></h2>
<p>Setiap fitur ini adalah pengukuran kuantitatif dari komposisi kimia sampel anggur.</p>
<ol class="arabic simple">
<li><p><strong>Alcohol (Alkohol)</strong></p>
<ul class="simple">
<li><p><strong>Penjelasan:</strong> Mengukur kadar alkohol dalam anggur. Ini adalah salah satu komponen utama yang menentukan kekuatan dan karakteristik rasa anggur.</p></li>
<li><p><strong>Jenis Data:</strong> Numerik (kontinu/riil).</p></li>
</ul>
</li>
<li><p><strong>Malic_acid (Asam Malat)</strong></p>
<ul class="simple">
<li><p><strong>Penjelasan:</strong> Mengukur kadar asam malat. Asam malat adalah salah satu asam organik utama yang ditemukan dalam anggur dan buah-buahan lainnya. Kadar asam ini memengaruhi keasaman dan rasa anggur.</p></li>
<li><p><strong>Jenis Data:</strong> Numerik (kontinu/riil).</p></li>
</ul>
</li>
<li><p><strong>Ash (Abu)</strong></p>
<ul class="simple">
<li><p><strong>Penjelasan:</strong> Mengukur kandungan abu dalam anggur. Abu adalah residu padat yang tersisa setelah anggur dibakar sempurna, yang mencerminkan kandungan mineral anorganik di dalamnya.</p></li>
<li><p><strong>Jenis Data:</strong> Numerik (kontinu/riil).</p></li>
</ul>
</li>
<li><p><strong>Alcalinity_of_ash (Alkalinitas Abu)</strong></p>
<ul class="simple">
<li><p><strong>Penjelasan:</strong> Mengukur alkalinitas (kebasaan) abu. Ini menunjukkan tingkat keasaman atau kebasaan tanah tempat anggur ditanam, yang dapat memengaruhi komposisi mineral anggur.</p></li>
<li><p><strong>Jenis Data:</strong> Numerik (kontinu/riil).</p></li>
</ul>
</li>
<li><p><strong>Magnesium (Magnesium)</strong></p>
<ul class="simple">
<li><p><strong>Penjelasan:</strong> Mengukur kandungan magnesium dalam anggur. Magnesium adalah mineral penting yang memengaruhi proses fermentasi dan juga merupakan komponen nutrisi.</p></li>
<li><p><strong>Jenis Data:</strong> Numerik (kontinu/riil).</p></li>
</ul>
</li>
<li><p><strong>Total_phenols (Total Fenol)</strong></p>
<ul class="simple">
<li><p><strong>Penjelasan:</strong> Mengukur jumlah total senyawa fenolik dalam anggur. Fenol adalah senyawa yang memengaruhi warna, rasa (terutama kepahitan dan <em>astringency</em>), dan sifat antioksidan anggur.</p></li>
<li><p><strong>Jenis Data:</strong> Numerik (kontinu/riil).</p></li>
</ul>
</li>
<li><p><strong>Flavanoids (Flavanoid)</strong></p>
<ul class="simple">
<li><p><strong>Penjelasan:</strong> Mengukur kandungan flavanoid. Flavanoid adalah sub-kategori penting dari fenol yang berkontribusi signifikan terhadap warna, rasa, dan manfaat kesehatan anggur (seperti sifat antioksidan).</p></li>
<li><p><strong>Jenis Data:</strong> Numerik (kontinu/riil).</p></li>
</ul>
</li>
<li><p><strong>Nonflavanoid_phenols (Fenol Non-Flavanoid)</strong></p>
<ul class="simple">
<li><p><strong>Penjelasan:</strong> Mengukur kadar fenol yang bukan flavanoid. Ini adalah jenis senyawa fenolik lain yang juga memengaruhi karakteristik anggur.</p></li>
<li><p><strong>Jenis Data:</strong> Numerik (kontinu/riil).</p></li>
</ul>
</li>
<li><p><strong>Proanthocyanins (Proantosianin)</strong></p>
<ul class="simple">
<li><p><strong>Penjelasan:</strong> Mengukur kandungan proantosianin. Ini adalah jenis tanin yang bertanggung jawab atas <em>astringency</em> (rasa kelat atau sepet) dan kekeruhan pada anggur, serta memiliki sifat antioksidan.</p></li>
<li><p><strong>Jenis Data:</strong> Numerik (kontinu/riil).</p></li>
</ul>
</li>
<li><p><strong>Color_intensity (Intensitas Warna)</strong></p>
<ul class="simple">
<li><p><strong>Penjelasan:</strong> Mengukur seberapa pekat atau kuat warna anggur. Ini adalah indikator visual penting yang bisa sangat bervariasi antar varietas.</p></li>
<li><p><strong>Jenis Data:</strong> Numerik (kontinu/riil).</p></li>
</ul>
</li>
<li><p><strong>Hue (Rona/Warna Sejati)</strong></p>
<ul class="simple">
<li><p><strong>Penjelasan:</strong> Mengukur rona atau corak warna anggur, yang mengacu pada spektrum warna (misalnya, kemerahan, keunguan). Ini melengkapi informasi dari intensitas warna.</p></li>
<li><p><strong>Jenis Data:</strong> Numerik (kontinu/riil).</p></li>
</ul>
</li>
<li><p><strong>OD280/OD315_of_diluted_wines (OD280/OD315 Anggur yang Diencerkan)</strong></p>
<ul class="simple">
<li><p><strong>Penjelasan:</strong> Ini adalah rasio absorbansi pada panjang gelombang 280 nm dan 315 nm dari anggur yang telah diencerkan. Rasio ini biasanya terkait dengan kandungan protein dan senyawa fenolik tertentu, yang dapat memengaruhi kejernihan dan stabilitas anggur.</p></li>
<li><p><strong>Jenis Data:</strong> Numerik (kontinu/riil).</p></li>
</ul>
</li>
<li><p><strong>Proline (Prolin)</strong></p>
<ul class="simple">
<li><p><strong>Penjelasan:</strong> Mengukur kandungan asam amino prolin. Prolin adalah salah satu asam amino yang paling melimpah dalam anggur dan dapat berperan dalam pembentukan rasa dan aroma, serta menjadi indikator kematangan anggur.</p></li>
<li><p><strong>Jenis Data:</strong> Numerik (kontinu/riil).</p></li>
</ul>
</li>
</ol>
</section>
<hr class="docutils" />
<section id="variabel-target-output">
<h2>Variabel Target (Output):<a class="headerlink" href="#variabel-target-output" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p><strong>class (Kelas/Varietas)</strong></p>
<ul>
<li><p><strong>Penjelasan:</strong> Ini adalah label atau variabel target yang ingin Anda prediksi. Dalam dataset ini, <code class="docutils literal notranslate"><span class="pre">class</span></code> menunjukkan <strong>varietas anggur</strong> tempat sampel tersebut berasal. Nilainya adalah bilangan bulat: <code class="docutils literal notranslate"><span class="pre">1</span></code>, <code class="docutils literal notranslate"><span class="pre">2</span></code>, atau <code class="docutils literal notranslate"><span class="pre">3</span></code>, masing-masing mewakili satu dari tiga kultivar anggur yang berbeda.</p></li>
<li><p><strong>Jenis Data:</strong> Kategorikal (disajikan sebagai Integer).</p></li>
</ul>
</li>
</ul>
</section>
<section id="eksplorasi-data">
<h2><strong>Eksplorasi Data</strong><a class="headerlink" href="#eksplorasi-data" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ucimlrepo</span><span class="w"> </span><span class="kn">import</span> <span class="n">fetch_ucirepo</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">seaborn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sns</span>

<span class="c1"># --- 1. Mengambil Dataset ---</span>
<span class="n">wine</span> <span class="o">=</span> <span class="n">fetch_ucirepo</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="mi">109</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">wine</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">features</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">wine</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">targets</span>

<span class="c1"># Menggabungkan X dan y untuk eksplorasi lebih mudah</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;class&#39;</span><span class="p">:</span> <span class="s1">&#39;Target_Class&#39;</span><span class="p">})</span> <span class="c1"># Mengganti nama kolom target agar lebih jelas</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;--- Eksplorasi Kualitas Data Dataset Anggur ---&quot;</span><span class="p">)</span>

<span class="c1"># --- 2. Informasi Umum Dataset ---</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">## 2.1 Informasi Umum Dataset&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;------------------------------&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">info</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Jumlah Baris: </span><span class="si">{</span><span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Jumlah Kolom: </span><span class="si">{</span><span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>--- Eksplorasi Kualitas Data Dataset Anggur ---

## 2.1 Informasi Umum Dataset
------------------------------
&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 178 entries, 0 to 177
Data columns (total 14 columns):
 #   Column                        Non-Null Count  Dtype  
---  ------                        --------------  -----  
 0   Alcohol                       178 non-null    float64
 1   Malicacid                     178 non-null    float64
 2   Ash                           178 non-null    float64
 3   Alcalinity_of_ash             178 non-null    float64
 4   Magnesium                     178 non-null    int64  
 5   Total_phenols                 178 non-null    float64
 6   Flavanoids                    178 non-null    float64
 7   Nonflavanoid_phenols          178 non-null    float64
 8   Proanthocyanins               178 non-null    float64
 9   Color_intensity               178 non-null    float64
 10  Hue                           178 non-null    float64
 11  0D280_0D315_of_diluted_wines  178 non-null    float64
 12  Proline                       178 non-null    int64  
 13  Target_Class                  178 non-null    int64  
dtypes: float64(11), int64(3)
memory usage: 19.6 KB
None

Jumlah Baris: 178
Jumlah Kolom: 14
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># --- 3. Memeriksa Missing Values (Nilai Hilang) ---</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">## 2.2 Memeriksa Missing Values&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;---------------------------------&quot;</span><span class="p">)</span>
<span class="n">missing_values</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">missing_percentage</span> <span class="o">=</span> <span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">))</span> <span class="o">*</span> <span class="mi">100</span>
<span class="n">missing_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;Jumlah Hilang&#39;</span><span class="p">:</span> <span class="n">missing_values</span><span class="p">,</span> <span class="s1">&#39;Persentase Hilang (%)&#39;</span><span class="p">:</span> <span class="n">missing_percentage</span><span class="p">})</span>
<span class="nb">print</span><span class="p">(</span><span class="n">missing_df</span><span class="p">[</span><span class="n">missing_df</span><span class="p">[</span><span class="s1">&#39;Jumlah Hilang&#39;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">])</span>

<span class="k">if</span> <span class="n">missing_df</span><span class="p">[</span><span class="s1">&#39;Jumlah Hilang&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Tidak ada missing values (nilai hilang) dalam dataset ini.&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Ada missing values dalam dataset ini. Perlu penanganan lebih lanjut.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>## 2.2 Memeriksa Missing Values
---------------------------------
Empty DataFrame
Columns: [Jumlah Hilang, Persentase Hilang (%)]
Index: []
Tidak ada missing values (nilai hilang) dalam dataset ini.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># --- 4. Memeriksa Duplikasi Data ---</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">## 2.3 Memeriksa Duplikasi Data&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;--------------------------------&quot;</span><span class="p">)</span>
<span class="n">duplicate_rows</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">duplicated</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Jumlah baris duplikat: </span><span class="si">{</span><span class="n">duplicate_rows</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="k">if</span> <span class="n">duplicate_rows</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Tidak ada duplikasi baris dalam dataset ini.&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Ada duplikasi baris dalam dataset ini. Pertimbangkan untuk menghapusnya.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>## 2.3 Memeriksa Duplikasi Data
--------------------------------
Jumlah baris duplikat: 0
Tidak ada duplikasi baris dalam dataset ini.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># --- 5. Statistik Deskriptif ---</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">## 2.4 Statistik Deskriptif Semua Fitur&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;----------------------------------------&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">describe</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>## 2.4 Statistik Deskriptif Semua Fitur
----------------------------------------
          Alcohol   Malicacid         Ash  Alcalinity_of_ash   Magnesium  \
count  178.000000  178.000000  178.000000         178.000000  178.000000   
mean    13.000618    2.336348    2.366517          19.494944   99.741573   
std      0.811827    1.117146    0.274344           3.339564   14.282484   
min     11.030000    0.740000    1.360000          10.600000   70.000000   
25%     12.362500    1.602500    2.210000          17.200000   88.000000   
50%     13.050000    1.865000    2.360000          19.500000   98.000000   
75%     13.677500    3.082500    2.557500          21.500000  107.000000   
max     14.830000    5.800000    3.230000          30.000000  162.000000   

       Total_phenols  Flavanoids  Nonflavanoid_phenols  Proanthocyanins  \
count     178.000000  178.000000            178.000000       178.000000   
mean        2.295112    2.029270              0.361854         1.590899   
std         0.625851    0.998859              0.124453         0.572359   
min         0.980000    0.340000              0.130000         0.410000   
25%         1.742500    1.205000              0.270000         1.250000   
50%         2.355000    2.135000              0.340000         1.555000   
75%         2.800000    2.875000              0.437500         1.950000   
max         3.880000    5.080000              0.660000         3.580000   

       Color_intensity         Hue  0D280_0D315_of_diluted_wines      Proline  \
count       178.000000  178.000000                    178.000000   178.000000   
mean          5.058090    0.957449                      2.611685   746.893258   
std           2.318286    0.228572                      0.709990   314.907474   
min           1.280000    0.480000                      1.270000   278.000000   
25%           3.220000    0.782500                      1.937500   500.500000   
50%           4.690000    0.965000                      2.780000   673.500000   
75%           6.200000    1.120000                      3.170000   985.000000   
max          13.000000    1.710000                      4.000000  1680.000000   

       Target_Class  
count    178.000000  
mean       1.938202  
std        0.775035  
min        1.000000  
25%        1.000000  
50%        2.000000  
75%        3.000000  
max        3.000000  
</pre></div>
</div>
</div>
</div>
</section>
<section id="visualisasi-data">
<h2><strong>Visualisasi Data</strong><a class="headerlink" href="#visualisasi-data" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># --- 6. Mengidentifikasi Outlier (Menggunakan Box Plot) ---</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">## 2.5 Mengidentifikasi Outlier (dengan Box Plot)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-----------------------------------------------&quot;</span><span class="p">)</span>

<span class="c1"># Membuat box plot untuk setiap fitur numerik</span>
<span class="c1"># Exclude &#39;Target_Class&#39; dari box plot outlier karena itu adalah label</span>
<span class="n">numerical_features</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;float64&#39;</span><span class="p">,</span> <span class="s1">&#39;int64&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;Target_Class&#39;</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">12</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">feature</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">numerical_features</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># Menyesuaikan grid agar pas dengan jumlah fitur</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="n">feature</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">feature</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span> <span class="c1"># Hapus label y agar tidak tumpang tindih</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Box Plot untuk Setiap Fitur (Mengidentifikasi Outlier)&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.02</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Dari Box Plot:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;- Titik-titik di luar &#39;whiskers&#39; (garis batas atas dan bawah) menunjukkan potensi outlier.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;- Perhatikan fitur-fitur seperti &#39;Magnesium&#39;, &#39;Proline&#39;, &#39;Malic_acid&#39;, &#39;Ash&#39;, &#39;Alcalinity_of_ash&#39;, &#39;Proanthocyanins&#39;, dan &#39;Color_intensity&#39; yang menunjukkan adanya sejumlah outlier.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;- Kehadiran outlier perlu diinvestigasi lebih lanjut; apakah itu kesalahan input atau memang nilai yang wajar tetapi ekstrem.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>## 2.5 Mengidentifikasi Outlier (dengan Box Plot)
-----------------------------------------------
</pre></div>
</div>
<img alt="_images/53e76f12e9551a6904ca27264b6e36377f086a1bbb83a4799ef7fb39015c1908.png" src="_images/53e76f12e9551a6904ca27264b6e36377f086a1bbb83a4799ef7fb39015c1908.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Dari Box Plot:
- Titik-titik di luar &#39;whiskers&#39; (garis batas atas dan bawah) menunjukkan potensi outlier.
- Perhatikan fitur-fitur seperti &#39;Magnesium&#39;, &#39;Proline&#39;, &#39;Malic_acid&#39;, &#39;Ash&#39;, &#39;Alcalinity_of_ash&#39;, &#39;Proanthocyanins&#39;, dan &#39;Color_intensity&#39; yang menunjukkan adanya sejumlah outlier.
- Kehadiran outlier perlu diinvestigasi lebih lanjut; apakah itu kesalahan input atau memang nilai yang wajar tetapi ekstrem.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># --- 7. Distribusi Variabel Target ---</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">## 2.6 Distribusi Variabel Target (Class)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;------------------------------------------&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Target_Class&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Visualisasi Distribusi Kelas Target:&quot;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;Target_Class&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Distribusi Kelas Varietas Anggur&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Varietas Anggur (Kelas)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Jumlah Sampel&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Distribusi kelas (varietas anggur) tampaknya cukup seimbang, meskipun Kelas 2 memiliki jumlah sampel sedikit lebih banyak daripada yang lain, ini bagus untuk pelatihan model klasifikasi.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>## 2.6 Distribusi Variabel Target (Class)
------------------------------------------
Target_Class
2    71
1    59
3    48
Name: count, dtype: int64

Visualisasi Distribusi Kelas Target:
</pre></div>
</div>
<img alt="_images/e21634f8af35131069f8f146a5909ddc7b790f684e9c7ba13ba05d5d7662c085.png" src="_images/e21634f8af35131069f8f146a5909ddc7b790f684e9c7ba13ba05d5d7662c085.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Distribusi kelas (varietas anggur) tampaknya cukup seimbang, meskipun Kelas 2 memiliki jumlah sampel sedikit lebih banyak daripada yang lain, ini bagus untuk pelatihan model klasifikasi.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ucimlrepo</span><span class="w"> </span><span class="kn">import</span> <span class="n">fetch_ucirepo</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">seaborn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sns</span>

<span class="c1"># --- Inisialisasi Dataset ---</span>
<span class="n">wine</span> <span class="o">=</span> <span class="n">fetch_ucirepo</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="mi">109</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">wine</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">features</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">wine</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">targets</span>

<span class="c1"># Gabungkan X dan y ke dalam satu DataFrame untuk kemudahan eksplorasi</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;class&#39;</span><span class="p">:</span> <span class="s1">&#39;Target_Class&#39;</span><span class="p">})</span> <span class="c1"># Ganti nama kolom target</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;--- Visualisasi Dataset Anggur ---&quot;</span><span class="p">)</span>

<span class="c1"># Atur opsi tampilan Pandas agar semua kolom ditampilkan tanpa terpotong</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.max_columns&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.width&#39;</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>

<span class="c1"># --- 1. Distribusi Setiap Fitur Numerik (Histogram dan KDE Plot) ---</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">## 1. Distribusi Setiap Fitur Numerik&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;---------------------------------------&quot;</span><span class="p">)</span>

<span class="c1"># Pilih hanya fitur numerik (kecuali kolom target)</span>
<span class="n">numerical_features</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;float64&#39;</span><span class="p">,</span> <span class="s1">&#39;int64&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;Target_Class&#39;</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">15</span><span class="p">))</span> <span class="c1"># Ukuran keseluruhan figure</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">feature</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">numerical_features</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># Menyesuaikan grid agar pas dengan jumlah fitur</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">feature</span><span class="p">],</span> <span class="n">kde</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1"># kde=True menambahkan Kurva Estimasi Kepadatan</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Distribusi </span><span class="si">{</span><span class="n">feature</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span> <span class="c1"># Hapus label x agar tidak tumpang tindih</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span> <span class="c1"># Hapus label y agar tidak tumpang tindih</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Distribusi Fitur Kimia Anggur&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.02</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Observasi: Banyak fitur menunjukkan distribusi yang menyerupai lonceng (mendekati normal) atau sedikit miring (skewed).&quot;</span><span class="p">)</span>


<span class="c1"># --- 2. Matriks Korelasi Antar Fitur ---</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">## 2. Matriks Korelasi Antar Fitur&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-----------------------------------&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="c1"># Hitung matriks korelasi (tidak termasuk kolom target untuk korelasi fitur vs fitur)</span>
<span class="n">correlation_matrix</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">correlation_matrix</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;coolwarm&#39;</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s2">&quot;.2f&quot;</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Matriks Korelasi Antar Fitur Kimia Anggur&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Observasi:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;- Angka mendekati 1 atau -1 menunjukkan korelasi yang kuat (positif atau negatif).&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;- Contoh: &#39;Total_phenols&#39; dan &#39;Flavanoids&#39; memiliki korelasi positif yang sangat kuat (mendekati 1).&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;- Contoh: &#39;Alcohol&#39; dan &#39;Proline&#39; memiliki korelasi positif yang cukup kuat.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;- Korelasi tinggi antar fitur bisa mengindikasikan multikolinearitas, yang perlu diperhatikan pada beberapa model.&quot;</span><span class="p">)</span>


<span class="c1"># --- 3. Hubungan Fitur dengan Kelas Target (Box Plot per Kelas) ---</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">## 3. Hubungan Fitur dengan Kelas Target&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-----------------------------------------&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">15</span><span class="p">))</span> <span class="c1"># Ukuran keseluruhan figure</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">feature</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">numerical_features</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># Menyesuaikan grid</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;Target_Class&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">feature</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">feature</span><span class="si">}</span><span class="s1"> per Kelas&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Varietas Anggur (Kelas)&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Distribusi Fitur Berdasarkan Varietas Anggur (Kelas)&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.02</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Observasi:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;- Box plot ini menunjukkan bagaimana distribusi (rata-rata, penyebaran, outlier) setiap fitur bervariasi antar varietas anggur.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;- Beberapa fitur seperti &#39;Alcohol&#39;, &#39;Flavanoids&#39;, dan &#39;OD280/OD315_of_diluted_wines&#39; menunjukkan perbedaan yang jelas antar kelas.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;- Contoh: &#39;Alcohol&#39; Kelas 1 cenderung lebih tinggi daripada Kelas 2 dan 3. &#39;Flavanoids&#39; Kelas 1 juga jauh lebih tinggi dari kelas lainnya.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;- Fitur-fitur dengan perbedaan yang jelas antar kelas ini kemungkinan besar akan sangat penting dalam memprediksi varietas anggur.&quot;</span><span class="p">)</span>

<span class="c1"># Mengembalikan opsi tampilan Pandas ke default</span>
<span class="n">pd</span><span class="o">.</span><span class="n">reset_option</span><span class="p">(</span><span class="s1">&#39;display.max_columns&#39;</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">reset_option</span><span class="p">(</span><span class="s1">&#39;display.width&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>--- Visualisasi Dataset Anggur ---

## 1. Distribusi Setiap Fitur Numerik
---------------------------------------
</pre></div>
</div>
<img alt="_images/27aeeb4c9dc82a5cbbc3516ad4740e740f704377298fae3ae80768e7f1bfe890.png" src="_images/27aeeb4c9dc82a5cbbc3516ad4740e740f704377298fae3ae80768e7f1bfe890.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Observasi: Banyak fitur menunjukkan distribusi yang menyerupai lonceng (mendekati normal) atau sedikit miring (skewed).

## 2. Matriks Korelasi Antar Fitur
-----------------------------------
</pre></div>
</div>
<img alt="_images/469eaf32fa80f8fc7533d198647d6bb0abe6f372fdb66001f2172c51358f67ba.png" src="_images/469eaf32fa80f8fc7533d198647d6bb0abe6f372fdb66001f2172c51358f67ba.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Observasi:
- Angka mendekati 1 atau -1 menunjukkan korelasi yang kuat (positif atau negatif).
- Contoh: &#39;Total_phenols&#39; dan &#39;Flavanoids&#39; memiliki korelasi positif yang sangat kuat (mendekati 1).
- Contoh: &#39;Alcohol&#39; dan &#39;Proline&#39; memiliki korelasi positif yang cukup kuat.
- Korelasi tinggi antar fitur bisa mengindikasikan multikolinearitas, yang perlu diperhatikan pada beberapa model.

## 3. Hubungan Fitur dengan Kelas Target
-----------------------------------------
</pre></div>
</div>
<img alt="_images/f7d1171c39d1058121614e08881162aab7ad80ebeed8da93e2a06bc273d498b4.png" src="_images/f7d1171c39d1058121614e08881162aab7ad80ebeed8da93e2a06bc273d498b4.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Observasi:
- Box plot ini menunjukkan bagaimana distribusi (rata-rata, penyebaran, outlier) setiap fitur bervariasi antar varietas anggur.
- Beberapa fitur seperti &#39;Alcohol&#39;, &#39;Flavanoids&#39;, dan &#39;OD280/OD315_of_diluted_wines&#39; menunjukkan perbedaan yang jelas antar kelas.
- Contoh: &#39;Alcohol&#39; Kelas 1 cenderung lebih tinggi daripada Kelas 2 dan 3. &#39;Flavanoids&#39; Kelas 1 juga jauh lebih tinggi dari kelas lainnya.
- Fitur-fitur dengan perbedaan yang jelas antar kelas ini kemungkinan besar akan sangat penting dalam memprediksi varietas anggur.
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="preprocessing-data">
<h1><strong>Preprocessing Data</strong><a class="headerlink" href="#preprocessing-data" title="Link to this heading">#</a></h1>
<hr class="docutils" />
<p>Kode pra-pemrosesan yang saya berikan menggunakan dua rumus matematika utama yang sangat umum dalam <em>machine learning</em>:</p>
<ol class="arabic simple">
<li><p><strong>Standardisasi (StandardScaler):</strong> Menggunakan rumus <strong>Z-score normalization</strong>.</p></li>
<li><p><strong>Reduksi Dimensi (PCA):</strong> Menggunakan rumus <strong>Analisis Komponen Utama (Principal Component Analysis)</strong>.</p></li>
</ol>
<hr class="docutils" />
<section id="rumus-untuk-standardisasi-standardscaler">
<h2>1. Rumus untuk Standardisasi (StandardScaler)<a class="headerlink" href="#rumus-untuk-standardisasi-standardscaler" title="Link to this heading">#</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">StandardScaler</span></code> mengubah setiap nilai fitur (variabel) <span class="math notranslate nohighlight">\(x\)</span> ke dalam skala standar dengan rumus <strong>Z-score</strong>:</p>
<div class="math notranslate nohighlight">
\[z = \frac{x - \mu}{\sigma}\]</div>
<p><strong>Di mana:</strong></p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(z\)</span> adalah nilai fitur yang telah distandardisasi.</p></li>
<li><p><span class="math notranslate nohighlight">\(x\)</span> adalah nilai fitur asli (sebelum standardisasi).</p></li>
<li><p><span class="math notranslate nohighlight">\(\mu\)</span> (mu) adalah <strong>rata-rata (mean)</strong> dari semua nilai untuk fitur tersebut dalam dataset pelatihan.</p></li>
<li><p><span class="math notranslate nohighlight">\(\sigma\)</span> (sigma) adalah <strong>standar deviasi</strong> dari semua nilai untuk fitur tersebut dalam dataset pelatihan.</p></li>
</ul>
<p><strong>Tujuan:</strong> Rumus ini memastikan bahwa setelah transformasi, setiap fitur akan memiliki rata-rata nol (<span class="math notranslate nohighlight">\(0\)</span>) dan standar deviasi satu (<span class="math notranslate nohighlight">\(1\)</span>). Ini sangat penting agar fitur dengan rentang nilai yang besar tidak mendominasi model yang sensitif terhadap skala.</p>
</section>
<hr class="docutils" />
<section id="rumus-untuk-reduksi-dimensi-pca-principal-component-analysis">
<h2>2. Rumus untuk Reduksi Dimensi (PCA - Principal Component Analysis)<a class="headerlink" href="#rumus-untuk-reduksi-dimensi-pca-principal-component-analysis" title="Link to this heading">#</a></h2>
<p>PCA adalah teknik yang lebih kompleks yang melibatkan aljabar linier. Ini tidak hanya satu rumus sederhana, melainkan serangkaian langkah matematis untuk mengubah fitur-fitur asli yang mungkin saling berkorelasi menjadi satu set fitur baru yang tidak berkorelasi, yang disebut <strong>komponen utama (principal components)</strong>.</p>
<p>Langkah-langkah utamanya secara konseptual adalah:</p>
<ol class="arabic simple">
<li><p><strong>Standardisasi Data:</strong> (Ini adalah alasan mengapa kita sering menerapkan <code class="docutils literal notranslate"><span class="pre">StandardScaler</span></code> sebelum PCA). PCA sangat sensitif terhadap skala fitur, jadi semua fitur harus diskalakan terlebih dahulu.</p></li>
<li><p><strong>Perhitungan Matriks Kovarians:</strong> Menghitung matriks yang menunjukkan bagaimana setiap pasangan fitur berkorelasi satu sama lain.</p></li>
<li><p><strong>Perhitungan Eigenvalue dan Eigenvector:</strong></p>
<ul class="simple">
<li><p><strong>Eigenvector</strong> adalah arah atau “vektor” baru yang memaksimalkan varians data. Komponen utama adalah eigenvector dari matriks kovarians.</p></li>
<li><p><strong>Eigenvalue</strong> adalah nilai yang terkait dengan setiap eigenvector, menunjukkan seberapa banyak varians data yang ditangkap oleh eigenvector tersebut.</p></li>
</ul>
</li>
<li><p><strong>Pemilihan Komponen Utama:</strong> Mengurutkan eigenvector berdasarkan eigenvalue-nya (dari terbesar ke terkecil) dan memilih <span class="math notranslate nohighlight">\(k\)</span> eigenvector teratas yang menjelaskan sebagian besar varians data. <span class="math notranslate nohighlight">\(k\)</span> ini adalah <code class="docutils literal notranslate"><span class="pre">n_components</span></code> yang kita tentukan (misalnya, <code class="docutils literal notranslate"><span class="pre">n_components=2</span></code>).</p></li>
<li><p><strong>Transformasi Data:</strong> Memproyeksikan data asli (yang sudah distandardisasi) ke ruang yang dibentuk oleh <span class="math notranslate nohighlight">\(k\)</span> komponen utama yang dipilih. Ini menghasilkan kumpulan fitur baru yang lebih sedikit dimensinya.</p></li>
</ol>
<p><strong>Tujuan:</strong> Mengurangi jumlah fitur (dimensi) dalam dataset sambil mempertahankan sebanyak mungkin informasi (varians) yang relevan, seringkali untuk visualisasi atau untuk membantu model yang terbebani oleh terlalu banyak fitur.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ucimlrepo</span><span class="w"> </span><span class="kn">import</span> <span class="n">fetch_ucirepo</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.decomposition</span><span class="w"> </span><span class="kn">import</span> <span class="n">PCA</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">seaborn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sns</span>

<span class="c1"># --- 1. Mengambil Dataset ---</span>
<span class="n">wine</span> <span class="o">=</span> <span class="n">fetch_ucirepo</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="mi">109</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">wine</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">features</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">wine</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">targets</span>

<span class="c1"># Menggabungkan X dan y ke dalam satu DataFrame untuk memudahkan eksplorasi awal</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;class&#39;</span><span class="p">:</span> <span class="s1">&#39;Target_Class&#39;</span><span class="p">})</span> <span class="c1"># Mengganti nama kolom target</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;--- Pra-pemrosesan Data Anggur ---&quot;</span><span class="p">)</span>

<span class="c1"># --- 2. Pemisahan Fitur (X) dan Target (y) Kembali ---</span>
<span class="c1"># Penting: Scaling biasanya dilakukan pada X.</span>
<span class="c1"># y tidak di-scale karena itu adalah label kategori.</span>
<span class="n">X_features</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;Target_Class&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># Drop kolom target untuk mendapatkan fitur</span>
<span class="n">y_target</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Target_Class&#39;</span><span class="p">]</span>               <span class="c1"># Ambil kolom target</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">## 2.1 Penskalaan (Standardisasi) Fitur&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-----------------------------------------&quot;</span><span class="p">)</span>

<span class="c1"># Inisialisasi StandardScaler</span>
<span class="c1"># StandardScaler akan mengubah fitur sehingga rata-ratanya menjadi 0 dan standar deviasinya 1.</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>

<span class="c1"># Melakukan standardisasi pada fitur-fitur X</span>
<span class="n">X_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_features</span><span class="p">)</span>

<span class="c1"># Mengubah kembali array NumPy yang dihasilkan oleh scaler menjadi DataFrame Pandas</span>
<span class="c1"># Ini memudahkan untuk melihat hasilnya dan mempertahankan nama kolom</span>
<span class="n">X_scaled_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X_scaled</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">X_features</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Tampilan 5 Baris Pertama Fitur Setelah Standardisasi (X_scaled_df):&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X_scaled_df</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Statistik Deskriptif Fitur Setelah Standardisasi:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X_scaled_df</span><span class="o">.</span><span class="n">describe</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Observasi: Rata-rata setiap fitur kini mendekati 0 dan standar deviasinya mendekati 1.&quot;</span><span class="p">)</span>

<span class="c1"># --- 3. Reduksi Dimensi (Principal Component Analysis - PCA) ---</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">## 2.2 Reduksi Dimensi (PCA - Opsional)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-----------------------------------------&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;PCA dapat digunakan untuk mengurangi jumlah fitur sambil mempertahankan sebagian besar informasi.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Ini juga bagus untuk visualisasi data dimensi tinggi ke 2D atau 3D.&quot;</span><span class="p">)</span>

<span class="c1"># Inisialisasi PCA untuk mengurangi dimensi menjadi 2 komponen utama</span>
<span class="c1"># Kita akan gunakan data yang sudah di-scale (X_scaled)</span>
<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">X_pca</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_scaled</span><span class="p">)</span>

<span class="c1"># Mengubah hasil PCA menjadi DataFrame untuk kemudahan melihat</span>
<span class="n">X_pca_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">X_pca</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Principal Component 1&#39;</span><span class="p">,</span> <span class="s1">&#39;Principal Component 2&#39;</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">5 Baris Pertama Fitur Setelah Reduksi Dimensi dengan PCA (2 Komponen):&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X_pca_df</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Variansi yang Dijelaskan oleh 2 Komponen Utama: </span><span class="si">{</span><span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>

<span class="c1"># --- Visualisasi Hasil PCA (untuk melihat pengelompokan berdasarkan kelas) ---</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Visualisasi Data Setelah Reduksi Dimensi (PCA) Berdasarkan Kelas:&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="s1">&#39;Principal Component 1&#39;</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="s1">&#39;Principal Component 2&#39;</span><span class="p">,</span>
    <span class="n">hue</span><span class="o">=</span><span class="n">y_target</span><span class="p">,</span> <span class="c1"># Menggunakan kolom target untuk mewarnai titik</span>
    <span class="n">palette</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">,</span>
    <span class="n">data</span><span class="o">=</span><span class="n">X_pca_df</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Data Anggur Setelah PCA (2 Komponen) Berdasarkan Varietas Anggur&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Komponen Utama 1&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Komponen Utama 2&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Observasi dari Visualisasi PCA:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;- Anda bisa melihat bagaimana ketiga varietas anggur cenderung mengelompok secara terpisah di ruang 2D yang baru.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;- Ini menunjukkan bahwa 2 komponen utama ini sudah cukup baik dalam membedakan kelas.&quot;</span><span class="p">)</span>

<span class="c1"># --- 4. Catatan Penting: Pembagian Data Train/Test ---</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">## Catatan Penting: Pembagian Data Train/Test&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-----------------------------------------&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Dalam praktik nyata, langkah pra-pemrosesan (scaling, dll.) harus dilakukan setelah membagi data menjadi set pelatihan dan pengujian, untuk mencegah &#39;data leakage&#39;.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Misalnya: scaler.fit(X_train) kemudian scaler.transform(X_train) dan scaler.transform(X_test).&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>--- Pra-pemrosesan Data Anggur ---

## 2.1 Penskalaan (Standardisasi) Fitur
-----------------------------------------
Tampilan 5 Baris Pertama Fitur Setelah Standardisasi (X_scaled_df):
    Alcohol  Malicacid       Ash  Alcalinity_of_ash  Magnesium  Total_phenols  \
0  1.518613  -0.562250  0.232053          -1.169593   1.913905       0.808997   
1  0.246290  -0.499413 -0.827996          -2.490847   0.018145       0.568648   
2  0.196879   0.021231  1.109334          -0.268738   0.088358       0.808997   
3  1.691550  -0.346811  0.487926          -0.809251   0.930918       2.491446   
4  0.295700   0.227694  1.840403           0.451946   1.281985       0.808997   

   Flavanoids  Nonflavanoid_phenols  Proanthocyanins  Color_intensity  \
0    1.034819             -0.659563         1.224884         0.251717   
1    0.733629             -0.820719        -0.544721        -0.293321   
2    1.215533             -0.498407         2.135968         0.269020   
3    1.466525             -0.981875         1.032155         1.186068   
4    0.663351              0.226796         0.401404        -0.319276   

        Hue  0D280_0D315_of_diluted_wines   Proline  
0  0.362177                      1.847920  1.013009  
1  0.406051                      1.113449  0.965242  
2  0.318304                      0.788587  1.395148  
3 -0.427544                      1.184071  2.334574  
4  0.362177                      0.449601 -0.037874  

Statistik Deskriptif Fitur Setelah Standardisasi:
            Alcohol     Malicacid           Ash  Alcalinity_of_ash  \
count  1.780000e+02  1.780000e+02  1.780000e+02       1.780000e+02   
mean  -8.382808e-16 -1.197544e-16 -8.370333e-16      -3.991813e-17   
std    1.002821e+00  1.002821e+00  1.002821e+00       1.002821e+00   
min   -2.434235e+00 -1.432983e+00 -3.679162e+00      -2.671018e+00   
25%   -7.882448e-01 -6.587486e-01 -5.721225e-01      -6.891372e-01   
50%    6.099988e-02 -4.231120e-01 -2.382132e-02       1.518295e-03   
75%    8.361286e-01  6.697929e-01  6.981085e-01       6.020883e-01   
max    2.259772e+00  3.109192e+00  3.156325e+00       3.154511e+00   

          Magnesium  Total_phenols    Flavanoids  Nonflavanoid_phenols  \
count  1.780000e+02     178.000000  1.780000e+02          1.780000e+02   
mean  -3.991813e-17       0.000000 -3.991813e-16          3.592632e-16   
std    1.002821e+00       1.002821  1.002821e+00          1.002821e+00   
min   -2.088255e+00      -2.107246 -1.695971e+00         -1.868234e+00   
25%   -8.244151e-01      -0.885468 -8.275393e-01         -7.401412e-01   
50%   -1.222817e-01       0.095960  1.061497e-01         -1.760948e-01   
75%    5.096384e-01       0.808997  8.490851e-01          6.095413e-01   
max    4.371372e+00       2.539515  3.062832e+00          2.402403e+00   

       Proanthocyanins  Color_intensity           Hue  \
count     1.780000e+02     1.780000e+02  1.780000e+02   
mean     -1.197544e-16     2.494883e-17  1.995907e-16   
std       1.002821e+00     1.002821e+00  1.002821e+00   
min      -2.069034e+00    -1.634288e+00 -2.094732e+00   
25%      -5.972835e-01    -7.951025e-01 -7.675624e-01   
50%      -6.289785e-02    -1.592246e-01  3.312687e-02   
75%       6.291754e-01     4.939560e-01  7.131644e-01   
max       3.485073e+00     3.435432e+00  3.301694e+00   

       0D280_0D315_of_diluted_wines       Proline  
count                  1.780000e+02  1.780000e+02  
mean                   3.193450e-16 -1.596725e-16  
std                    1.002821e+00  1.002821e+00  
min                   -1.895054e+00 -1.493188e+00  
25%                   -9.522483e-01 -7.846378e-01  
50%                    2.377348e-01 -2.337204e-01  
75%                    7.885875e-01  7.582494e-01  
max                    1.960915e+00  2.971473e+00  

Observasi: Rata-rata setiap fitur kini mendekati 0 dan standar deviasinya mendekati 1.

## 2.2 Reduksi Dimensi (PCA - Opsional)
-----------------------------------------
PCA dapat digunakan untuk mengurangi jumlah fitur sambil mempertahankan sebagian besar informasi.
Ini juga bagus untuk visualisasi data dimensi tinggi ke 2D atau 3D.

5 Baris Pertama Fitur Setelah Reduksi Dimensi dengan PCA (2 Komponen):
   Principal Component 1  Principal Component 2
0               3.316751               1.443463
1               2.209465              -0.333393
2               2.516740               1.031151
3               3.757066               2.756372
4               1.008908               0.869831

Variansi yang Dijelaskan oleh 2 Komponen Utama: 55.41%

Visualisasi Data Setelah Reduksi Dimensi (PCA) Berdasarkan Kelas:
</pre></div>
</div>
<img alt="_images/7c8c6f3054c0b5163b59f750f9019890547a33e5ca0e4c8d20dac991f58cfd3c.png" src="_images/7c8c6f3054c0b5163b59f750f9019890547a33e5ca0e4c8d20dac991f58cfd3c.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Observasi dari Visualisasi PCA:
- Anda bisa melihat bagaimana ketiga varietas anggur cenderung mengelompok secara terpisah di ruang 2D yang baru.
- Ini menunjukkan bahwa 2 komponen utama ini sudah cukup baik dalam membedakan kelas.

## Catatan Penting: Pembagian Data Train/Test
-----------------------------------------
Dalam praktik nyata, langkah pra-pemrosesan (scaling, dll.) harus dilakukan setelah membagi data menjadi set pelatihan dan pengujian, untuk mencegah &#39;data leakage&#39;.
Misalnya: scaler.fit(X_train) kemudian scaler.transform(X_train) dan scaler.transform(X_test).
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="deteksi-outlier-menggunakan-local-outlier-factor-lof">
<h1><strong>deteksi outlier menggunakan Local Outlier Factor (LOF)</strong><a class="headerlink" href="#deteksi-outlier-menggunakan-local-outlier-factor-lof" title="Link to this heading">#</a></h1>
<hr class="docutils" />
</section>
<section id="menggunakan-local-outlier-factor-lof-untuk-mendeteksi-outlier-pada-data-anggur-dan-ingin-memahami-konsep-konsep-di-baliknya-secara-berurutan-ini-adalah-pilihan-yang-sangat-baik-karena-lof-adalah-metode-yang-kuat-untuk-mendeteksi-outlier-berbasis-kepadatan">
<h1>menggunakan <strong>Local Outlier Factor (LOF)</strong> untuk mendeteksi <em>outlier</em> pada data anggur, dan ingin memahami konsep-konsep di baliknya secara berurutan. Ini adalah pilihan yang sangat baik karena LOF adalah metode yang kuat untuk mendeteksi <em>outlier</em> berbasis kepadatan.<a class="headerlink" href="#menggunakan-local-outlier-factor-lof-untuk-mendeteksi-outlier-pada-data-anggur-dan-ingin-memahami-konsep-konsep-di-baliknya-secara-berurutan-ini-adalah-pilihan-yang-sangat-baik-karena-lof-adalah-metode-yang-kuat-untuk-mendeteksi-outlier-berbasis-kepadatan" title="Link to this heading">#</a></h1>
<section id="konsep-lof">
<h2>Konsep LOF<a class="headerlink" href="#konsep-lof" title="Link to this heading">#</a></h2>
<p>LOF adalah algoritma deteksi <em>outlier</em> yang menilai anomali suatu objek dengan mengukur seberapa terpencilnya objek tersebut terhadap lingkungannya sendiri. Ia membandingkan kepadatan lokal objek dengan kepadatan lokal tetangganya.</p>
<section id="k-distance-dan-k-neighbors">
<h3>1. K-distance dan K-neighbors<a class="headerlink" href="#k-distance-dan-k-neighbors" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Konsep:</strong></p>
<ul>
<li><p><strong>K-neighbors:</strong> Untuk setiap titik data (misalnya, sampel anggur), kita mengidentifikasi <span class="math notranslate nohighlight">\(k\)</span> titik data terdekat dengannya. <span class="math notranslate nohighlight">\(k\)</span> adalah parameter yang Anda tentukan (misalnya, jika <span class="math notranslate nohighlight">\(k=5\)</span>, kita mencari 5 tetangga terdekat).</p></li>
<li><p><strong>K-distance:</strong> Jarak ke tetangga ke-<span class="math notranslate nohighlight">\(k\)</span> dari suatu titik data. Jika Anda mengurutkan semua jarak dari titik pusat ke titik-titik lain dalam urutan menaik, K-distance adalah jarak pada posisi ke-<span class="math notranslate nohighlight">\(k\)</span>.</p></li>
</ul>
</li>
<li><p><strong>Analogi:</strong> Bayangkan Anda adalah sebuah rumah di perumahan. Jika <span class="math notranslate nohighlight">\(k=3\)</span>, Anda mencari 3 rumah terdekat dari rumah Anda. K-distance Anda adalah jarak ke rumah ke-3 terdekat tersebut.</p></li>
</ul>
</section>
<section id="reachability-distance-rd">
<h3>2. Reachability Distance (RD)<a class="headerlink" href="#reachability-distance-rd" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Konsep:</strong></p>
<ul>
<li><p>RD dirancang untuk “menghaluskan” variasi kecil dalam kepadatan. Ini adalah konsep kunci LOF.</p></li>
<li><p>Untuk menghitung <em>reachability distance</em> dari titik A ke titik B (<span class="math notranslate nohighlight">\(RD(A,B)\)</span>):</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(RD(A,B) = \text{max}(\text{K-distance}(B), \text{distance}(A,B))\)</span></p></li>
</ul>
</li>
<li><p>Ini berarti RD adalah <strong>jarak maksimum</strong> antara K-distance dari titik B <em>atau</em> jarak aktual dari A ke B.</p></li>
<li><p><strong>Tujuan:</strong> Jika titik B adalah tetangga dekat A dan memiliki kepadatan tinggi (K-distance kecil), RD akan menjadi jarak aktual A ke B. Namun, jika B adalah tetangga A tetapi berada di wilayah yang jarang (K-distance besar), RD akan lebih besar, memperhitungkan “keterpencilannya” B itu sendiri. Ini mencegah <em>outlier</em> yang sangat jauh membuat kepadatan lokal tampak lebih rendah dari yang seharusnya jika hanya menggunakan jarak Euclidean biasa.</p></li>
</ul>
</li>
<li><p><strong>Analogi:</strong> Seberapa “mudah” bagi Anda untuk “mencapai” rumah tetangga. Jika tetangga itu sendiri sudah jauh dari tetangga-tetangganya (K-distance-nya besar), maka jarak untuk “mencapainya” dari Anda akan diperhitungkan juga.</p></li>
</ul>
</section>
<section id="local-reachability-density-lrd">
<h3>3. Local Reachability Density (LRD)<a class="headerlink" href="#local-reachability-density-lrd" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Konsep:</strong></p>
<ul>
<li><p>LRD mengukur <strong>kepadatan lokal</strong> suatu titik data. Ini adalah kebalikan (invers) dari rata-rata <em>reachability distance</em> dari titik tersebut ke semua K-neighbors-nya.</p></li>
<li><p>Semakin kecil nilai LRD, semakin rendah kepadatan di sekitar titik tersebut.</p></li>
<li><p>Rumusnya adalah:
$<span class="math notranslate nohighlight">\(LRD(O) = 1 / \left( \frac{\sum_{P \in N_k(O)} RD(O,P)}{|N_k(O)|} \right)\)</span><span class="math notranslate nohighlight">\(
  Di mana \)</span>N_k(O)<span class="math notranslate nohighlight">\( adalah K-neighbors dari objek \)</span>O$.</p></li>
</ul>
</li>
<li><p><strong>Analogi:</strong> Seberapa padat lingkungan Anda? Jika rata-rata jarak “capai” ke tetangga-tetangga Anda sangat besar, berarti lingkungan Anda tidak padat (LRD rendah).</p></li>
</ul>
</section>
<section id="local-outlier-factor-lof">
<h3>4. Local Outlier Factor (LOF)<a class="headerlink" href="#local-outlier-factor-lof" title="Link to this heading">#</a></h3>
<ul>
<li><p><strong>Konsep:</strong></p>
<ul>
<li><p>LOF adalah rasio rata-rata LRD K-neighbors dari suatu objek dengan LRD objek itu sendiri.</p></li>
<li><div class="math notranslate nohighlight">
\[LOF(O) = \frac{\sum_{P \in N_k(O)} \frac{LRD(P)}{LRD(O)}}{|N_k(O)|}\]</div>
</li>
<li><p><strong>Interpretasi Nilai LOF:</strong></p>
<ul class="simple">
<li><p><strong>LOF ≈ 1:</strong> Objek memiliki kepadatan yang mirip dengan tetangganya, kemungkinan <strong>bukan outlier</strong>.</p></li>
<li><p><strong>LOF &gt; 1:</strong> Objek memiliki kepadatan yang <strong>lebih rendah</strong> dari tetangganya, yang berarti lebih terpencil dan merupakan <strong>potensi outlier</strong>. Semakin tinggi nilai LOF, semakin tinggi kemungkinan menjadi <em>outlier</em>.</p></li>
<li><p><strong>LOF &lt; 1:</strong> Objek memiliki kepadatan yang <strong>lebih tinggi</strong> dari tetangganya (ini jarang terjadi dan biasanya tidak mengindikasikan <em>outlier</em>).</p></li>
</ul>
</li>
</ul>
</li>
<li><p><strong>Analogi:</strong> Apakah lingkungan Anda lebih jarang daripada lingkungan tetangga Anda? Jika ya (LOF &gt; 1), Anda mungkin tinggal di tempat yang terpencil.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">seaborn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sns</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.neighbors</span><span class="w"> </span><span class="kn">import</span> <span class="n">LocalOutlierFactor</span> <span class="c1"># Mengimpor LOF</span>


<span class="c1"># Mengatur opsi tampilan Pandas agar semua kolom ditampilkan tanpa terpotong</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.max_columns&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.width&#39;</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span><span class="o">*</span><span class="mi">50</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;## Deteksi Outlier Menggunakan Local Outlier Factor (LOF)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span><span class="o">*</span><span class="mi">50</span><span class="p">)</span>

<span class="c1"># Inisialisasi model LOF</span>
<span class="c1"># n_neighbors: Jumlah tetangga yang akan digunakan untuk perhitungan LOF (nilai umum 20)</span>
<span class="c1"># contamination: Perkiraan proporsi outlier dalam dataset (0.01 - 0.10 adalah nilai umum)</span>
<span class="c1">#                &#39;auto&#39; akan mencoba memperkirakan berdasarkan data.</span>
<span class="c1"># novelty=False: Digunakan untuk deteksi outlier pada data yang sudah ada (bukan data baru)</span>
<span class="n">lof</span> <span class="o">=</span> <span class="n">LocalOutlierFactor</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">contamination</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="n">novelty</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Melatih model dan memprediksi outlier</span>
<span class="c1"># .fit_predict() mengembalikan -1 untuk outlier, 1 untuk inlier</span>
<span class="n">outlier_predictions_lof</span> <span class="o">=</span> <span class="n">lof</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">X_scaled_df</span><span class="p">)</span>

<span class="c1"># Menghitung jumlah outlier</span>
<span class="n">num_lof_outliers</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">outlier_predictions_lof</span><span class="p">)</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Jumlah outlier yang terdeteksi oleh LOF: </span><span class="si">{</span><span class="n">num_lof_outliers</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Menampilkan indeks baris yang dianggap outlier</span>
<span class="n">outlier_indices_lof</span> <span class="o">=</span> <span class="n">X_scaled_df</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="n">outlier_predictions_lof</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Indeks baris outlier yang terdeteksi oleh LOF: </span><span class="si">{</span><span class="n">outlier_indices_lof</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Mengambil nilai LOF score (semakin tinggi, semakin outlier)</span>
<span class="c1"># Perhatikan bahwa .negative_outlier_factor_() mengembalikan -LOF, jadi kita kalikan -1</span>
<span class="n">lof_scores</span> <span class="o">=</span> <span class="n">lof</span><span class="o">.</span><span class="n">negative_outlier_factor_</span>
<span class="n">lof_scores</span> <span class="o">=</span> <span class="o">-</span><span class="n">lof_scores</span> <span class="c1"># Ubah menjadi nilai LOF positif</span>

<span class="c1"># Menambahkan LOF score ke DataFrame untuk analisis lebih lanjut</span>
<span class="n">X_scaled_df_with_lof</span> <span class="o">=</span> <span class="n">X_scaled_df</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span> <span class="c1"># Buat salinan agar tidak memengaruhi df asli</span>
<span class="n">X_scaled_df_with_lof</span><span class="p">[</span><span class="s1">&#39;lof_score&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">lof_scores</span>
<span class="n">X_scaled_df_with_lof</span><span class="p">[</span><span class="s1">&#39;is_outlier_lof&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">outlier_predictions_lof</span> <span class="c1"># Tambahkan status outlier</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">--- 5 Baris Data dengan LOF Score Tertinggi (Potensi Outlier) ---&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X_scaled_df_with_lof</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s1">&#39;lof_score&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>

<span class="c1"># Visualisasi Distribusi LOF Scores</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">X_scaled_df_with_lof</span><span class="p">[</span><span class="s1">&#39;lof_score&#39;</span><span class="p">],</span> <span class="n">kde</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Distribusi LOF Scores&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;LOF Score&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Frekuensi&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Visualisasi Outlier berdasarkan LOF Score pada PCA (jika Anda sudah melakukan PCA)</span>
<span class="c1"># Anda perlu memastikan X_pca_df dan y_target tersedia jika ingin menjalankan bagian ini</span>
<span class="k">try</span><span class="p">:</span>
    <span class="c1"># Memastikan X_pca_df memiliki indeks yang sama dengan X_scaled_df_with_lof</span>
    <span class="c1"># Tambahkan kolom LOF status ke X_pca_df</span>
    <span class="n">X_pca_df_plot</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X_pca</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Principal Component 1&#39;</span><span class="p">,</span> <span class="s1">&#39;Principal Component 2&#39;</span><span class="p">])</span>
    <span class="n">X_pca_df_plot</span><span class="p">[</span><span class="s1">&#39;is_outlier_lof&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">outlier_predictions_lof</span>
    <span class="n">X_pca_df_plot</span><span class="p">[</span><span class="s1">&#39;Target_Class&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_target</span><span class="o">.</span><span class="n">values</span> <span class="c1"># Tambahkan kelas target untuk hue</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span>
        <span class="n">x</span><span class="o">=</span><span class="s1">&#39;Principal Component 1&#39;</span><span class="p">,</span>
        <span class="n">y</span><span class="o">=</span><span class="s1">&#39;Principal Component 2&#39;</span><span class="p">,</span>
        <span class="n">hue</span><span class="o">=</span><span class="s1">&#39;is_outlier_lof&#39;</span><span class="p">,</span> <span class="c1"># Warna berdasarkan status outlier</span>
        <span class="n">style</span><span class="o">=</span><span class="s1">&#39;is_outlier_lof&#39;</span><span class="p">,</span> <span class="c1"># Bentuk berdasarkan status outlier</span>
        <span class="n">palette</span><span class="o">=</span><span class="p">{</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span> <span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span> <span class="s1">&#39;blue&#39;</span><span class="p">},</span> <span class="c1"># Merah untuk outlier, biru untuk inlier</span>
        <span class="n">data</span><span class="o">=</span><span class="n">X_pca_df_plot</span><span class="p">,</span>
        <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="c1"># Ukuran titik</span>
        <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span> <span class="c1"># Transparansi</span>
    <span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Outlier LOF pada Data Anggur (PCA 2 Komponen)&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Komponen Utama 1&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Komponen Utama 2&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s1">&#39;LOF Status&#39;</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Outlier (-1)&#39;</span><span class="p">,</span> <span class="s1">&#39;Inlier (1)&#39;</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Visualisasi Outlier LOF pada ruang PCA berhasil ditampilkan.&quot;</span><span class="p">)</span>

<span class="k">except</span> <span class="ne">NameError</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Catatan: Visualisasi LOF pada PCA tidak ditampilkan karena &#39;X_pca&#39; atau &#39;y_target&#39; tidak ditemukan.&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Pastikan Anda telah menjalankan bagian kode PCA sebelumnya jika Anda ingin melihat visualisasi ini.&quot;</span><span class="p">)</span>


<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">--- Deteksi Outlier LOF Selesai ---&quot;</span><span class="p">)</span>

<span class="c1"># Mengembalikan opsi tampilan Pandas ke default</span>
<span class="n">pd</span><span class="o">.</span><span class="n">reset_option</span><span class="p">(</span><span class="s1">&#39;display.max_columns&#39;</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">reset_option</span><span class="p">(</span><span class="s1">&#39;display.width&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>==================================================
## Deteksi Outlier Menggunakan Local Outlier Factor (LOF)
==================================================
Jumlah outlier yang terdeteksi oleh LOF: 6
Indeks baris outlier yang terdeteksi oleh LOF: [59, 69, 73, 95, 121, 158]

--- 5 Baris Data dengan LOF Score Tertinggi (Potensi Outlier) ---
      Alcohol  Malicacid       Ash  Alcalinity_of_ash  Magnesium  Total_phenols  Flavanoids  Nonflavanoid_phenols  Proanthocyanins  Color_intensity       Hue  0D280_0D315_of_diluted_wines   Proline  lof_score  is_outlier_lof
121 -1.779545  -0.257044  3.156325           2.704083   1.352198       1.417883    3.062832              0.871420         0.489009         0.407442 -0.120430                      1.523058 -0.897687   1.906266              -1
69  -0.976623  -1.029035 -2.253579          -0.809251   3.599025      -0.713218   -0.752242             -1.787656         1.592822        -0.955153  1.415139                      0.647343 -0.092010   1.834240              -1
95  -0.655454  -0.732806 -0.608676          -0.148624   4.371372       0.328298    0.241685             -0.337251         2.959447        -1.063296  0.888658                      0.025868  0.605394   1.827155              -1
73  -0.013116  -0.598156  0.853460           3.154511   2.756465       1.610163    0.864145             -1.223610         0.646696        -0.738868  1.546759                      1.254694  0.758249   1.724562              -1
59  -0.778980  -1.253450 -3.679162          -2.671018  -0.824415      -0.504914   -1.465058             -0.659563        -2.051513        -1.344466  0.406051                     -1.118210 -0.722540   1.692308              -1
</pre></div>
</div>
<img alt="_images/fab5bc20e8d414ad2321a18688c16a9c65a0c8053262f9a28d8973227cd2451d.png" src="_images/fab5bc20e8d414ad2321a18688c16a9c65a0c8053262f9a28d8973227cd2451d.png" />
<img alt="_images/e7c8ae98cb6b2b0af0014cdfb54b5f55bdee1394758008647659fda59851d1d8.png" src="_images/e7c8ae98cb6b2b0af0014cdfb54b5f55bdee1394758008647659fda59851d1d8.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Visualisasi Outlier LOF pada ruang PCA berhasil ditampilkan.

--- Deteksi Outlier LOF Selesai ---
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="pengecekan-ulang-apakah-data-masih-memiliki-outlier">
<h1><strong>pengecekan ulang apakah data masih memiliki outlier</strong><a class="headerlink" href="#pengecekan-ulang-apakah-data-masih-memiliki-outlier" title="Link to this heading">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ucimlrepo</span><span class="w"> </span><span class="kn">import</span> <span class="n">fetch_ucirepo</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">seaborn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sns</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.neighbors</span><span class="w"> </span><span class="kn">import</span> <span class="n">LocalOutlierFactor</span> <span class="c1"># Mengimpor LOF</span>

<span class="c1"># Mengatur opsi tampilan Pandas agar semua kolom ditampilkan tanpa terpotong</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.max_columns&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.width&#39;</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;--- Pengecekan Ulang Keberadaan Outlier ---&quot;</span><span class="p">)</span>

<span class="c1"># --- 1. Mengambil dan Mempersiapkan Dataset ---</span>
<span class="c1"># Ini diperlukan untuk memastikan X_scaled_df dan y_target tersedia</span>
<span class="c1"># jika kode ini dijalankan secara terpisah.</span>
<span class="n">wine</span> <span class="o">=</span> <span class="n">fetch_ucirepo</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="mi">109</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">wine</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">features</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">wine</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">targets</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span> <span class="c1"># Pastikan y adalah Series</span>

<span class="c1"># Menggabungkan X dan y untuk analisis awal, lalu pisahkan lagi untuk scaling</span>
<span class="n">df_original</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df_original</span> <span class="o">=</span> <span class="n">df_original</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;class&#39;</span><span class="p">:</span> <span class="s1">&#39;Target_Class&#39;</span><span class="p">})</span>

<span class="n">X_features</span> <span class="o">=</span> <span class="n">df_original</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;Target_Class&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y_target</span> <span class="o">=</span> <span class="n">df_original</span><span class="p">[</span><span class="s1">&#39;Target_Class&#39;</span><span class="p">]</span>

<span class="c1"># Standardisasi Fitur</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_features</span><span class="p">)</span>
<span class="n">X_scaled_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X_scaled</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">X_features</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Dataset telah diambil dan fitur distandardisasi ke X_scaled_df.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Sekarang kita akan cek kembali outlier pada X_scaled_df.&quot;</span><span class="p">)</span>

<span class="c1"># --- 2. Pengecekan Outlier dengan Statistik Deskriptif (Z-score Check) ---</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">## 2. Pengecekan Outlier dengan Statistik Deskriptif (Z-score)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;----------------------------------------------------------------&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Meskipun sudah distandardisasi (rata-rata ~0, std ~1), nilai ekstrem masih bisa ada.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Kita akan melihat nilai min/max dan berapa jauh dari rata-rata (Z-score &gt; 3 atau &lt; -3).&quot;</span><span class="p">)</span>

<span class="c1"># Tampilkan statistik deskriptif untuk data yang diskalakan</span>
<span class="n">desc_scaled</span> <span class="o">=</span> <span class="n">X_scaled_df</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Statistik Deskriptif X_scaled_df:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">desc_scaled</span><span class="p">)</span>

<span class="n">outlier_zscore_count</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">zscore_threshold</span> <span class="o">=</span> <span class="mi">3</span> <span class="c1"># Ambang batas umum untuk Z-score</span>

<span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">X_scaled_df</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="c1"># Memeriksa apakah ada nilai yang Z-score-nya di luar ambang batas</span>
    <span class="n">num_outliers</span> <span class="o">=</span> <span class="n">X_scaled_df</span><span class="p">[(</span><span class="n">X_scaled_df</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">zscore_threshold</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">X_scaled_df</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">&lt;</span> <span class="o">-</span><span class="n">zscore_threshold</span><span class="p">)]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">num_outliers</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">outlier_zscore_count</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">num_outliers</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;- Fitur &#39;</span><span class="si">{</span><span class="n">col</span><span class="si">}</span><span class="s2">&#39;: Ditemukan </span><span class="si">{</span><span class="n">num_outliers</span><span class="si">}</span><span class="s2"> outlier (Z-score &gt; </span><span class="si">{</span><span class="n">zscore_threshold</span><span class="si">}</span><span class="s2"> atau &lt; -</span><span class="si">{</span><span class="n">zscore_threshold</span><span class="si">}</span><span class="s2">).&quot;</span><span class="p">)</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">outlier_zscore_count</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Tidak ada outlier yang terdeteksi di semua fitur berdasarkan ambang Z-score &gt; 3 atau &lt; -3.&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Ringkasan Outlier Z-score yang Ditemukan:&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">col</span><span class="p">,</span> <span class="n">count</span> <span class="ow">in</span> <span class="n">outlier_zscore_count</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  &#39;</span><span class="si">{</span><span class="n">col</span><span class="si">}</span><span class="s2">&#39;: </span><span class="si">{</span><span class="n">count</span><span class="si">}</span><span class="s2"> outlier&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Observasi: Nilai Z-score yang signifikan (misalnya di atas 3 atau di bawah -3) masih mengindikasikan adanya titik data yang jauh dari rata-rata fitur tersebut, bahkan setelah standardisasi.&quot;</span><span class="p">)</span>


<span class="c1"># --- 3. Pengecekan Outlier dengan Visualisasi Box Plot ---</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">## 3. Pengecekan Outlier dengan Visualisasi Box Plot&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;----------------------------------------------------&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Box plot secara visual menampilkan outlier (titik-titik di luar &#39;kumis&#39;).&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">12</span><span class="p">))</span> <span class="c1"># Ukuran figure untuk menampung semua box plot</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">feature</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">X_scaled_df</span><span class="o">.</span><span class="n">columns</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># Membuat grid subplot 4x4</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">X_scaled_df</span><span class="p">[</span><span class="n">feature</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Box Plot: </span><span class="si">{</span><span class="n">feature</span><span class="si">}</span><span class="s1"> (Scaled)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span> <span class="c1"># Hapus label y untuk kerapian</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">(</span><span class="n">rect</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.03</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mf">0.98</span><span class="p">])</span> <span class="c1"># Sesuaikan layout agar tidak tumpang tindih</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Pengecekan Outlier per Fitur (Data Terstandardisasi)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Observasi: Box plot masih menunjukkan titik-titik outlier yang sama seperti pada data asli, hanya saja skalanya telah berubah.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Ini menegaskan bahwa outlier adalah karakteristik intrinsik dari data tersebut, bukan artefak dari skala yang berbeda.&quot;</span><span class="p">)</span>


<span class="c1"># --- 4. Pengecekan Outlier dengan Local Outlier Factor (LOF) ---</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">## 4. Pengecekan Outlier dengan Local Outlier Factor (LOF)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;------------------------------------------------------------&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;LOF mendeteksi outlier berdasarkan kepadatan lokal titik data.&quot;</span><span class="p">)</span>

<span class="c1"># Inisialisasi model LOF</span>
<span class="c1"># n_neighbors: Jumlah tetangga yang akan digunakan. 20-25 adalah pilihan umum.</span>
<span class="c1"># contamination: Perkiraan proporsi outlier. &#39;auto&#39; mencoba memperkirakan.</span>
<span class="n">lof</span> <span class="o">=</span> <span class="n">LocalOutlierFactor</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">contamination</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="n">novelty</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Melatih model dan memprediksi outlier (-1 untuk outlier, 1 untuk inlier)</span>
<span class="n">outlier_predictions_lof</span> <span class="o">=</span> <span class="n">lof</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">X_scaled_df</span><span class="p">)</span>

<span class="c1"># Menghitung jumlah outlier yang terdeteksi oleh LOF</span>
<span class="n">num_lof_outliers</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">outlier_predictions_lof</span><span class="p">)</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Jumlah outlier yang terdeteksi oleh LOF: </span><span class="si">{</span><span class="n">num_lof_outliers</span><span class="si">}</span><span class="s2"> dari </span><span class="si">{</span><span class="n">X_scaled_df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2"> sampel.&quot;</span><span class="p">)</span>

<span class="c1"># Mendapatkan skor LOF (nilai negatif, semakin rendah semakin outlier, jadi kita balik tanda)</span>
<span class="n">lof_scores</span> <span class="o">=</span> <span class="o">-</span><span class="n">lof</span><span class="o">.</span><span class="n">negative_outlier_factor_</span>
<span class="n">X_scaled_df</span><span class="p">[</span><span class="s1">&#39;lof_score&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">lof_scores</span>
<span class="n">X_scaled_df</span><span class="p">[</span><span class="s1">&#39;is_outlier_lof&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">outlier_predictions_lof</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">5 Sampel dengan LOF Score Tertinggi (Potensi Outlier Terbesar):&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X_scaled_df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s1">&#39;lof_score&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>

<span class="c1"># Visualisasi Outlier LOF pada PCA (jika Anda sudah melakukan PCA dan ingin melihatnya lagi)</span>
<span class="c1"># Membutuhkan variabel X_pca dari kode sebelumnya. Jika belum ada, bagian ini akan dilewati.</span>
<span class="k">try</span><span class="p">:</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.decomposition</span><span class="w"> </span><span class="kn">import</span> <span class="n">PCA</span> <span class="c1"># Impor PCA di sini jika belum diimpor</span>
    <span class="c1"># Ulangi PCA untuk visualisasi yang bersih dengan LOF status</span>
    <span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">X_pca_recalculated</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_scaled_df</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">&#39;lof_score&#39;</span><span class="p">,</span> <span class="s1">&#39;is_outlier_lof&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">))</span>
    <span class="n">X_pca_df_for_plot</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X_pca_recalculated</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Principal Component 1&#39;</span><span class="p">,</span> <span class="s1">&#39;Principal Component 2&#39;</span><span class="p">])</span>
    <span class="n">X_pca_df_for_plot</span><span class="p">[</span><span class="s1">&#39;is_outlier_lof&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">outlier_predictions_lof</span>
    <span class="n">X_pca_df_for_plot</span><span class="p">[</span><span class="s1">&#39;Target_Class&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_target</span><span class="o">.</span><span class="n">values</span> <span class="c1"># Tambahkan kelas target untuk hue</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span>
        <span class="n">x</span><span class="o">=</span><span class="s1">&#39;Principal Component 1&#39;</span><span class="p">,</span>
        <span class="n">y</span><span class="o">=</span><span class="s1">&#39;Principal Component 2&#39;</span><span class="p">,</span>
        <span class="n">hue</span><span class="o">=</span><span class="s1">&#39;is_outlier_lof&#39;</span><span class="p">,</span> <span class="c1"># Warna berdasarkan status outlier</span>
        <span class="n">style</span><span class="o">=</span><span class="s1">&#39;is_outlier_lof&#39;</span><span class="p">,</span> <span class="c1"># Bentuk berdasarkan status outlier</span>
        <span class="n">palette</span><span class="o">=</span><span class="p">{</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span> <span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span> <span class="s1">&#39;blue&#39;</span><span class="p">},</span> <span class="c1"># Merah untuk outlier, biru untuk inlier</span>
        <span class="n">data</span><span class="o">=</span><span class="n">X_pca_df_for_plot</span><span class="p">,</span>
        <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="c1"># Ukuran titik</span>
        <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span> <span class="c1"># Transparansi</span>
    <span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Outlier LOF pada Data Anggur (PCA 2 Komponen)&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Komponen Utama 1&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Komponen Utama 2&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s1">&#39;LOF Status&#39;</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Outlier (-1)&#39;</span><span class="p">,</span> <span class="s1">&#39;Inlier (1)&#39;</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Visualisasi Outlier LOF pada ruang PCA telah ditampilkan.&quot;</span><span class="p">)</span>
<span class="k">except</span> <span class="ne">NameError</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Catatan: Visualisasi LOF pada PCA tidak ditampilkan karena PCA belum dijalankan atau &#39;X_pca&#39; tidak tersedia.&quot;</span><span class="p">)</span>


<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">--- Pengecekan Outlier Selesai ---&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Berdasarkan pengecekan ulang, data Anda memang masih mengandung beberapa titik data yang teridentifikasi sebagai outlier oleh berbagai metode.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Keputusan untuk menangani (menghapus, mengubah, atau membiarkan) outlier ini akan tergantung pada domain masalah dan sensitivitas model machine learning yang akan Anda gunakan.&quot;</span><span class="p">)</span>

<span class="c1"># Mengembalikan opsi tampilan Pandas ke default</span>
<span class="n">pd</span><span class="o">.</span><span class="n">reset_option</span><span class="p">(</span><span class="s1">&#39;display.max_columns&#39;</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">reset_option</span><span class="p">(</span><span class="s1">&#39;display.width&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>--- Pengecekan Ulang Keberadaan Outlier ---

Dataset telah diambil dan fitur distandardisasi ke X_scaled_df.
Sekarang kita akan cek kembali outlier pada X_scaled_df.

## 2. Pengecekan Outlier dengan Statistik Deskriptif (Z-score)
----------------------------------------------------------------
Meskipun sudah distandardisasi (rata-rata ~0, std ~1), nilai ekstrem masih bisa ada.
Kita akan melihat nilai min/max dan berapa jauh dari rata-rata (Z-score &gt; 3 atau &lt; -3).

Statistik Deskriptif X_scaled_df:
            Alcohol     Malicacid           Ash  Alcalinity_of_ash     Magnesium  Total_phenols    Flavanoids  Nonflavanoid_phenols  Proanthocyanins  Color_intensity           Hue  0D280_0D315_of_diluted_wines       Proline
count  1.780000e+02  1.780000e+02  1.780000e+02       1.780000e+02  1.780000e+02     178.000000  1.780000e+02          1.780000e+02     1.780000e+02     1.780000e+02  1.780000e+02                  1.780000e+02  1.780000e+02
mean  -8.382808e-16 -1.197544e-16 -8.370333e-16      -3.991813e-17 -3.991813e-17       0.000000 -3.991813e-16          3.592632e-16    -1.197544e-16     2.494883e-17  1.995907e-16                  3.193450e-16 -1.596725e-16
std    1.002821e+00  1.002821e+00  1.002821e+00       1.002821e+00  1.002821e+00       1.002821  1.002821e+00          1.002821e+00     1.002821e+00     1.002821e+00  1.002821e+00                  1.002821e+00  1.002821e+00
min   -2.434235e+00 -1.432983e+00 -3.679162e+00      -2.671018e+00 -2.088255e+00      -2.107246 -1.695971e+00         -1.868234e+00    -2.069034e+00    -1.634288e+00 -2.094732e+00                 -1.895054e+00 -1.493188e+00
25%   -7.882448e-01 -6.587486e-01 -5.721225e-01      -6.891372e-01 -8.244151e-01      -0.885468 -8.275393e-01         -7.401412e-01    -5.972835e-01    -7.951025e-01 -7.675624e-01                 -9.522483e-01 -7.846378e-01
50%    6.099988e-02 -4.231120e-01 -2.382132e-02       1.518295e-03 -1.222817e-01       0.095960  1.061497e-01         -1.760948e-01    -6.289785e-02    -1.592246e-01  3.312687e-02                  2.377348e-01 -2.337204e-01
75%    8.361286e-01  6.697929e-01  6.981085e-01       6.020883e-01  5.096384e-01       0.808997  8.490851e-01          6.095413e-01     6.291754e-01     4.939560e-01  7.131644e-01                  7.885875e-01  7.582494e-01
max    2.259772e+00  3.109192e+00  3.156325e+00       3.154511e+00  4.371372e+00       2.539515  3.062832e+00          2.402403e+00     3.485073e+00     3.435432e+00  3.301694e+00                  1.960915e+00  2.971473e+00
- Fitur &#39;Malicacid&#39;: Ditemukan 1 outlier (Z-score &gt; 3 atau &lt; -3).
- Fitur &#39;Ash&#39;: Ditemukan 3 outlier (Z-score &gt; 3 atau &lt; -3).
- Fitur &#39;Alcalinity_of_ash&#39;: Ditemukan 1 outlier (Z-score &gt; 3 atau &lt; -3).
- Fitur &#39;Magnesium&#39;: Ditemukan 2 outlier (Z-score &gt; 3 atau &lt; -3).
- Fitur &#39;Flavanoids&#39;: Ditemukan 1 outlier (Z-score &gt; 3 atau &lt; -3).
- Fitur &#39;Proanthocyanins&#39;: Ditemukan 1 outlier (Z-score &gt; 3 atau &lt; -3).
- Fitur &#39;Color_intensity&#39;: Ditemukan 1 outlier (Z-score &gt; 3 atau &lt; -3).
- Fitur &#39;Hue&#39;: Ditemukan 1 outlier (Z-score &gt; 3 atau &lt; -3).

Ringkasan Outlier Z-score yang Ditemukan:
  &#39;Malicacid&#39;: 1 outlier
  &#39;Ash&#39;: 3 outlier
  &#39;Alcalinity_of_ash&#39;: 1 outlier
  &#39;Magnesium&#39;: 2 outlier
  &#39;Flavanoids&#39;: 1 outlier
  &#39;Proanthocyanins&#39;: 1 outlier
  &#39;Color_intensity&#39;: 1 outlier
  &#39;Hue&#39;: 1 outlier

Observasi: Nilai Z-score yang signifikan (misalnya di atas 3 atau di bawah -3) masih mengindikasikan adanya titik data yang jauh dari rata-rata fitur tersebut, bahkan setelah standardisasi.

## 3. Pengecekan Outlier dengan Visualisasi Box Plot
----------------------------------------------------
Box plot secara visual menampilkan outlier (titik-titik di luar &#39;kumis&#39;).
</pre></div>
</div>
<img alt="_images/77e13ac3486b195b3520f6fbc5bf4805e24959ff52eed9739b73e3a0ea075f35.png" src="_images/77e13ac3486b195b3520f6fbc5bf4805e24959ff52eed9739b73e3a0ea075f35.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Observasi: Box plot masih menunjukkan titik-titik outlier yang sama seperti pada data asli, hanya saja skalanya telah berubah.
Ini menegaskan bahwa outlier adalah karakteristik intrinsik dari data tersebut, bukan artefak dari skala yang berbeda.

## 4. Pengecekan Outlier dengan Local Outlier Factor (LOF)
------------------------------------------------------------
LOF mendeteksi outlier berdasarkan kepadatan lokal titik data.
Jumlah outlier yang terdeteksi oleh LOF: 6 dari 178 sampel.

5 Sampel dengan LOF Score Tertinggi (Potensi Outlier Terbesar):
      Alcohol  Malicacid       Ash  Alcalinity_of_ash  Magnesium  Total_phenols  Flavanoids  Nonflavanoid_phenols  Proanthocyanins  Color_intensity       Hue  0D280_0D315_of_diluted_wines   Proline  lof_score  is_outlier_lof
121 -1.779545  -0.257044  3.156325           2.704083   1.352198       1.417883    3.062832              0.871420         0.489009         0.407442 -0.120430                      1.523058 -0.897687   1.782321              -1
95  -0.655454  -0.732806 -0.608676          -0.148624   4.371372       0.328298    0.241685             -0.337251         2.959447        -1.063296  0.888658                      0.025868  0.605394   1.740432              -1
69  -0.976623  -1.029035 -2.253579          -0.809251   3.599025      -0.713218   -0.752242             -1.787656         1.592822        -0.955153  1.415139                      0.647343 -0.092010   1.719196              -1
73  -0.013116  -0.598156  0.853460           3.154511   2.756465       1.610163    0.864145             -1.223610         0.646696        -0.738868  1.546759                      1.254694  0.758249   1.651926              -1
59  -0.778980  -1.253450 -3.679162          -2.671018  -0.824415      -0.504914   -1.465058             -0.659563        -2.051513        -1.344466  0.406051                     -1.118210 -0.722540   1.554338              -1
</pre></div>
</div>
<img alt="_images/e7c8ae98cb6b2b0af0014cdfb54b5f55bdee1394758008647659fda59851d1d8.png" src="_images/e7c8ae98cb6b2b0af0014cdfb54b5f55bdee1394758008647659fda59851d1d8.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Visualisasi Outlier LOF pada ruang PCA telah ditampilkan.

--- Pengecekan Outlier Selesai ---
Berdasarkan pengecekan ulang, data Anda memang masih mengandung beberapa titik data yang teridentifikasi sebagai outlier oleh berbagai metode.
Keputusan untuk menangani (menghapus, mengubah, atau membiarkan) outlier ini akan tergantung pada domain masalah dan sensitivitas model machine learning yang akan Anda gunakan.
</pre></div>
</div>
</div>
</div>
</section>
<section id="menghapus-outlier-dengan-iqr">
<h1><strong>Menghapus Outlier dengan IQR</strong><a class="headerlink" href="#menghapus-outlier-dengan-iqr" title="Link to this heading">#</a></h1>
<hr class="docutils" />
<p>Kode Python  untuk mendeteksi dan menghapus <em>outlier</em> menggunakan metode <strong>Interquartile Range (IQR)</strong> didasarkan pada rumus matematika berikut:</p>
<hr class="docutils" />
<section id="rumus-matematika-deteksi-outlier-dengan-metode-iqr">
<h2>Rumus Matematika Deteksi Outlier dengan Metode IQR<a class="headerlink" href="#rumus-matematika-deteksi-outlier-dengan-metode-iqr" title="Link to this heading">#</a></h2>
<p>Metode IQR mendefinisikan <em>outlier</em> sebagai titik data yang berada di luar batas bawah (lower bound) atau batas atas (upper bound) yang dihitung berdasarkan kuartil data.</p>
<ol class="arabic simple">
<li><p><strong>Kuartil Pertama (Q1):</strong>
Nilai di mana 25% data berada di bawahnya.
$<span class="math notranslate nohighlight">\(Q1 = P_{25}\)</span>$</p></li>
<li><p><strong>Kuartil Ketiga (Q3):</strong>
Nilai di mana 75% data berada di bawahnya.
$<span class="math notranslate nohighlight">\(Q3 = P_{75}\)</span>$</p></li>
<li><p><strong>Rentang Antarkuartil (Interquartile Range / IQR):</strong>
Perbedaan antara Kuartil Ketiga dan Kuartil Pertama. Ini merepresentasikan rentang tengah 50% data.
$<span class="math notranslate nohighlight">\(IQR = Q3 - Q1\)</span>$</p></li>
<li><p><strong>Batas Bawah (Lower Bound):</strong>
Setiap nilai yang lebih kecil dari batas ini dianggap sebagai <em>outlier</em>.
$<span class="math notranslate nohighlight">\(\text{Lower Bound} = Q1 - 1.5 \times IQR\)</span>$</p></li>
<li><p><strong>Batas Atas (Upper Bound):</strong>
Setiap nilai yang lebih besar dari batas ini dianggap sebagai <em>outlier</em>.
$<span class="math notranslate nohighlight">\(\text{Upper Bound} = Q3 + 1.5 \times IQR\)</span>$</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="c1"># Asumsikan X dan y sudah ada dari fetch_ucirepo</span>
<span class="c1"># Contoh: X = wine.data.features ; y = wine.data.targets</span>

<span class="c1"># Hitung IQR untuk setiap kolom</span>
<span class="n">Q1</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="mf">0.25</span><span class="p">)</span>
<span class="n">Q3</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="mf">0.75</span><span class="p">)</span>
<span class="n">IQR</span> <span class="o">=</span> <span class="n">Q3</span> <span class="o">-</span> <span class="n">Q1</span>

<span class="c1"># Buat mask (True = data normal, False = outlier)</span>
<span class="n">mask</span> <span class="o">=</span> <span class="o">~</span><span class="p">((</span><span class="n">X</span> <span class="o">&lt;</span> <span class="p">(</span><span class="n">Q1</span> <span class="o">-</span> <span class="mf">1.5</span> <span class="o">*</span> <span class="n">IQR</span><span class="p">))</span> <span class="o">|</span> <span class="p">(</span><span class="n">X</span> <span class="o">&gt;</span> <span class="p">(</span><span class="n">Q3</span> <span class="o">+</span> <span class="mf">1.5</span> <span class="o">*</span> <span class="n">IQR</span><span class="p">)))</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Terapkan mask ke fitur dan target</span>
<span class="n">X_clean</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>
<span class="n">y_clean</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Jumlah data sebelum penghapusan: </span><span class="si">{</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Jumlah data setelah outlier dihapus: </span><span class="si">{</span><span class="n">X_clean</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Jumlah data sebelum penghapusan: 178
Jumlah data setelah outlier dihapus: 161
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="data-splitting">
<h1><strong>Data Splitting</strong><a class="headerlink" href="#data-splitting" title="Link to this heading">#</a></h1>
<p>pembagian data menjadi set pelatihan dan pengujian</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>

<span class="c1"># Membagi data menjadi training dan testing (80%:20%)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X_clean</span><span class="p">,</span>
    <span class="n">y_clean</span><span class="p">,</span>
    <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>         <span class="c1"># 20% untuk pengujian</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>       <span class="c1"># agar hasil selalu sama</span>
    <span class="n">stratify</span><span class="o">=</span><span class="n">y_clean</span>       <span class="c1"># menjaga proporsi label</span>
<span class="p">)</span>

<span class="c1"># Tampilkan hasil split</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Jumlah data pelatihan: </span><span class="si">{</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2"> baris&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Jumlah data pengujian: </span><span class="si">{</span><span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2"> baris&quot;</span><span class="p">)</span>

<span class="c1"># Distribusi label pada train dan test</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Distribusi label pada data pelatihan:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y_train</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Distribusi label pada data pengujian:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y_test</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Jumlah data pelatihan: 128 baris
Jumlah data pengujian: 33 baris

Distribusi label pada data pelatihan:
class
2    38.28
1    35.94
3    25.78
Name: proportion, dtype: float64

Distribusi label pada data pengujian:
class
1    36.36
2    36.36
3    27.27
Name: proportion, dtype: float64
</pre></div>
</div>
</div>
</div>
</section>
<section id="klasifikasi-dengan-k-nearest-neighbors-knn">
<h1><strong>Klasifikasi dengan K-Nearest Neighbors (KNN)</strong><a class="headerlink" href="#klasifikasi-dengan-k-nearest-neighbors-knn" title="Link to this heading">#</a></h1>
<p>Berikut adalah <strong>langkah-langkah lengkap algoritma K-Nearest Neighbors (KNN)</strong> menggunakan <strong>jarak Euclidean</strong>, termasuk <strong>rumus-rumus manualnya</strong> sampai prediksi selesai.</p>
<hr class="docutils" />
</section>
<section id="tujuan-knn">
<h1>🧭 <strong>Tujuan KNN:</strong><a class="headerlink" href="#tujuan-knn" title="Link to this heading">#</a></h1>
<p>Mengklasifikasikan suatu data uji (data baru) berdasarkan <strong>mayoritas kelas</strong> dari <strong>k tetangga terdekat</strong> di data latih.</p>
<hr class="docutils" />
</section>
<section id="langkah-langkah-knn-manual-dengan-jarak-euclidean">
<h1>✅ <strong>Langkah-Langkah KNN (Manual dengan Jarak Euclidean)</strong><a class="headerlink" href="#langkah-langkah-knn-manual-dengan-jarak-euclidean" title="Link to this heading">#</a></h1>
<section id="langkah-1-hitung-jarak-euclidean-antara-data-uji-dan-semua-data-latih">
<h2><strong>Langkah 1: Hitung Jarak Euclidean antara data uji dan semua data latih</strong><a class="headerlink" href="#langkah-1-hitung-jarak-euclidean-antara-data-uji-dan-semua-data-latih" title="Link to this heading">#</a></h2>
<p>Untuk setiap data latih <span class="math notranslate nohighlight">\(x_i\)</span>, hitung jarak ke data uji <span class="math notranslate nohighlight">\(x\)</span>:</p>
<div class="math notranslate nohighlight">
\[
\boxed{
d(x, x_i) = \sqrt{ \sum_{j=1}^{n} (x_j - x_{ij})^2 }
}
\]</div>
<p>Keterangan:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(x_j\)</span>: nilai fitur ke-<code class="docutils literal notranslate"><span class="pre">j</span></code> pada data uji</p></li>
<li><p><span class="math notranslate nohighlight">\(x_{ij}\)</span>: nilai fitur ke-<code class="docutils literal notranslate"><span class="pre">j</span></code> pada data latih ke-<code class="docutils literal notranslate"><span class="pre">i</span></code></p></li>
<li><p><span class="math notranslate nohighlight">\(n\)</span>: jumlah fitur</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="langkah-2-urutkan-data-latih-berdasarkan-jarak-terkecil">
<h2><strong>Langkah 2: Urutkan data latih berdasarkan jarak terkecil</strong><a class="headerlink" href="#langkah-2-urutkan-data-latih-berdasarkan-jarak-terkecil" title="Link to this heading">#</a></h2>
<ul>
<li><p>Setelah semua jarak dihitung, urutkan dari jarak terkecil ke terbesar.</p></li>
<li><p>Contoh:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Jarak</span><span class="p">:</span>
<span class="n">A</span><span class="p">:</span> <span class="mf">2.1</span>
<span class="n">B</span><span class="p">:</span> <span class="mf">1.2</span>
<span class="n">C</span><span class="p">:</span> <span class="mf">3.4</span>
</pre></div>
</div>
<p>Urutan: B, A, C</p>
</li>
</ul>
</section>
<hr class="docutils" />
<section id="langkah-3-ambil-k-tetangga-terdekat">
<h2><strong>Langkah 3: Ambil k tetangga terdekat</strong><a class="headerlink" href="#langkah-3-ambil-k-tetangga-terdekat" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Misal <span class="math notranslate nohighlight">\(k = 3\)</span>, maka ambil 3 data latih dengan jarak terkecil.</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="langkah-4-lakukan-voting-mayoritas-dari-label-k-tetangga">
<h2><strong>Langkah 4: Lakukan voting mayoritas dari label k tetangga</strong><a class="headerlink" href="#langkah-4-lakukan-voting-mayoritas-dari-label-k-tetangga" title="Link to this heading">#</a></h2>
<ul>
<li><p>Misalnya label dari 3 tetangga:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">B</span><span class="p">:</span> <span class="n">Class</span> <span class="n">A</span>
<span class="n">A</span><span class="p">:</span> <span class="n">Class</span> <span class="n">B</span>
<span class="n">C</span><span class="p">:</span> <span class="n">Class</span> <span class="n">A</span>
</pre></div>
</div>
</li>
<li><p>Maka voting:</p>
<ul class="simple">
<li><p>Class A = 2</p></li>
<li><p>Class B = 1
→ Prediksi akhir = <strong>Class A</strong></p></li>
</ul>
</li>
</ul>
</section>
<hr class="docutils" />
<section id="langkah-5-prediksi-selesai">
<h2><strong>Langkah 5: Prediksi selesai</strong><a class="headerlink" href="#langkah-5-prediksi-selesai" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Data uji diklasifikasikan ke kelas hasil voting mayoritas.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.neighbors</span><span class="w"> </span><span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">classification_report</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="c1"># ======== KNN ========</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">🧪 [KNN] Mulai Evaluasi Model...</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Train Model</span>
<span class="n">knn_model</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">knn_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Predict</span>
<span class="n">y_pred_knn</span> <span class="o">=</span> <span class="n">knn_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Evaluation</span>
<span class="n">acc_knn</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_knn</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;📈 Akurasi KNN: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">acc_knn</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">📋 Classification Report (KNN):&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_knn</span><span class="p">))</span>

<span class="c1"># Hasil Prediksi</span>
<span class="n">df_knn</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df_knn</span><span class="p">[</span><span class="s2">&quot;True Label&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_test</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df_knn</span><span class="p">[</span><span class="s2">&quot;Predicted Label&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_pred_knn</span>
<span class="n">df_knn</span><span class="p">[</span><span class="s2">&quot;Status&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_knn</span><span class="p">[</span><span class="s2">&quot;True Label&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="n">df_knn</span><span class="p">[</span><span class="s2">&quot;Predicted Label&quot;</span><span class="p">]</span>
<span class="n">df_knn</span><span class="p">[</span><span class="s2">&quot;Status&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_knn</span><span class="p">[</span><span class="s2">&quot;Status&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">({</span><span class="kc">True</span><span class="p">:</span> <span class="s2">&quot;✅ Benar&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">:</span> <span class="s2">&quot;❌ Salah&quot;</span><span class="p">})</span>

<span class="c1"># Output Prediksi</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">✅ Contoh Prediksi Benar (KNN):&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df_knn</span><span class="p">[</span><span class="n">df_knn</span><span class="p">[</span><span class="s2">&quot;Status&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;✅ Benar&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">head</span><span class="p">()</span><span class="o">.</span><span class="n">to_string</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">❌ Contoh Prediksi Salah (KNN):&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df_knn</span><span class="p">[</span><span class="n">df_knn</span><span class="p">[</span><span class="s2">&quot;Status&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;❌ Salah&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">head</span><span class="p">()</span><span class="o">.</span><span class="n">to_string</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>🧪 [KNN] Mulai Evaluasi Model...

📈 Akurasi KNN: 0.7576

📋 Classification Report (KNN):
              precision    recall  f1-score   support

           1       0.92      0.92      0.92        12
           2       0.65      0.92      0.76        12
           3       0.75      0.33      0.46         9

    accuracy                           0.76        33
   macro avg       0.77      0.72      0.71        33
weighted avg       0.77      0.76      0.74        33


✅ Contoh Prediksi Benar (KNN):
 Alcohol  Malicacid  Ash  Alcalinity_of_ash  Magnesium  Total_phenols  Flavanoids  Nonflavanoid_phenols  Proanthocyanins  Color_intensity  Hue  0D280_0D315_of_diluted_wines  Proline  True Label  Predicted Label  Status
   14.06       1.63 2.28               16.0        126           3.00        3.17                  0.24             2.10             5.65 1.09                          3.71      780           1                1 ✅ Benar
   12.72       1.75 2.28               22.5         84           1.38        1.76                  0.48             1.63             3.30 0.88                          2.42      488           2                2 ✅ Benar
   12.64       1.36 2.02               16.8        100           2.02        1.41                  0.53             0.62             5.75 0.98                          1.59      450           2                2 ✅ Benar
   14.02       1.68 2.21               16.0         96           2.65        2.33                  0.26             1.98             4.70 1.04                          3.59     1035           1                1 ✅ Benar
   14.22       3.99 2.51               13.2        128           3.00        3.04                  0.20             2.08             5.10 0.89                          3.53      760           1                1 ✅ Benar

❌ Contoh Prediksi Salah (KNN):
 Alcohol  Malicacid  Ash  Alcalinity_of_ash  Magnesium  Total_phenols  Flavanoids  Nonflavanoid_phenols  Proanthocyanins  Color_intensity  Hue  0D280_0D315_of_diluted_wines  Proline  True Label  Predicted Label  Status
   13.24       3.98 2.29               17.5        103           2.64        2.63                  0.32             1.66             4.36 0.82                          3.00      680           1                2 ❌ Salah
   13.69       3.26 2.54               20.0        107           1.83        0.56                  0.50             0.80             5.88 0.96                          1.82      680           3                2 ❌ Salah
   12.82       3.37 2.30               19.5         88           1.48        0.66                  0.40             0.97            10.26 0.72                          1.75      685           3                2 ❌ Salah
   12.25       4.72 2.54               21.0         89           1.38        0.47                  0.53             0.80             3.85 0.75                          1.27      720           3                2 ❌ Salah
   13.58       2.58 2.69               24.5        105           1.55        0.84                  0.39             1.54             8.66 0.74                          1.80      750           3                1 ❌ Salah
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="klasifikasi-dengan-naive-bayes-gaussiannb">
<h1><strong>Klasifikasi dengan Naive Bayes (GaussianNB)</strong><a class="headerlink" href="#klasifikasi-dengan-naive-bayes-gaussiannb" title="Link to this heading">#</a></h1>
<p>Berikut adalah <strong>langkah-langkah lengkap Naive Bayes</strong> untuk klasifikasi, lengkap dengan <strong>rumus-rumus pada setiap langkah</strong>, khususnya untuk <strong>Gaussian Naive Bayes</strong> (fitur numerik).</p>
<hr class="docutils" />
</section>
<section id="naive-bayes-classifier">
<h1>📘 <strong>Naive Bayes Classifier</strong><a class="headerlink" href="#naive-bayes-classifier" title="Link to this heading">#</a></h1>
<p>Naive Bayes adalah algoritma probabilistik yang menggunakan <strong>Teorema Bayes</strong> dengan asumsi fitur saling bebas (independen) satu sama lain.</p>
<hr class="docutils" />
</section>
<section id="langkah-langkah-rumus-naive-bayes">
<h1>✅ <strong>Langkah-langkah &amp; Rumus Naive Bayes</strong><a class="headerlink" href="#langkah-langkah-rumus-naive-bayes" title="Link to this heading">#</a></h1>
<hr class="docutils" />
<section id="langkah-1-hitung-probabilitas-prior-tiap-kelas">
<h2>🔹 <strong>Langkah 1: Hitung Probabilitas Prior Tiap Kelas</strong><a class="headerlink" href="#langkah-1-hitung-probabilitas-prior-tiap-kelas" title="Link to this heading">#</a></h2>
<p>Rumus prior:</p>
<div class="math notranslate nohighlight">
\[
P(C_k) = \frac{\text{jumlah sampel dalam kelas } C_k}{\text{jumlah total sampel}}
\]</div>
<p>Contoh:
Jika dari 100 data, 60 kelas “A” dan 40 kelas “B”, maka:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(P(A) = \frac{60}{100} = 0.6\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(P(B) = \frac{40}{100} = 0.4\)</span></p></li>
</ul>
</section>
<hr class="docutils" />
<section id="langkah-2-hitung-probabilitas-likelihood-untuk-tiap-fitur">
<h2>🔹 <strong>Langkah 2: Hitung Probabilitas Likelihood untuk Tiap Fitur</strong><a class="headerlink" href="#langkah-2-hitung-probabilitas-likelihood-untuk-tiap-fitur" title="Link to this heading">#</a></h2>
<section id="untuk-data-numerik-gaussian-naive-bayes-digunakan-distribusi-normal">
<h3>Untuk data numerik (Gaussian Naive Bayes), digunakan distribusi normal:<a class="headerlink" href="#untuk-data-numerik-gaussian-naive-bayes-digunakan-distribusi-normal" title="Link to this heading">#</a></h3>
<div class="math notranslate nohighlight">
\[
P(x_j \mid C_k) = \frac{1}{\sqrt{2\pi\sigma_{k,j}^2}} \cdot \exp\left( -\frac{(x_j - \mu_{k,j})^2}{2\sigma_{k,j}^2} \right)
\]</div>
<p>Keterangan:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(x_j\)</span>: nilai fitur ke-<code class="docutils literal notranslate"><span class="pre">j</span></code> dari data uji</p></li>
<li><p><span class="math notranslate nohighlight">\(\mu_{k,j}\)</span>: rata-rata fitur ke-<code class="docutils literal notranslate"><span class="pre">j</span></code> untuk kelas <span class="math notranslate nohighlight">\(C_k\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\sigma_{k,j}\)</span>: standar deviasi fitur ke-<code class="docutils literal notranslate"><span class="pre">j</span></code> untuk kelas <span class="math notranslate nohighlight">\(C_k\)</span></p></li>
</ul>
</section>
<section id="untuk-data-kategorikal-multinomial-bernoulli-naive-bayes">
<h3>Untuk data kategorikal (Multinomial/ Bernoulli Naive Bayes):<a class="headerlink" href="#untuk-data-kategorikal-multinomial-bernoulli-naive-bayes" title="Link to this heading">#</a></h3>
<div class="math notranslate nohighlight">
\[
P(x_j \mid C_k) = \frac{\text{jumlah kejadian fitur } x_j \text{ di kelas } C_k}{\text{jumlah total fitur di kelas } C_k}
\]</div>
</section>
</section>
<hr class="docutils" />
<section id="langkah-3-gunakan-teorema-bayes-untuk-probabilitas-posterior">
<h2>🔹 <strong>Langkah 3: Gunakan Teorema Bayes untuk Probabilitas Posterior</strong><a class="headerlink" href="#langkah-3-gunakan-teorema-bayes-untuk-probabilitas-posterior" title="Link to this heading">#</a></h2>
<div class="math notranslate nohighlight">
\[
P(C_k \mid X) = \frac{P(X \mid C_k) \cdot P(C_k)}{P(X)}
\]</div>
<p>Karena <span class="math notranslate nohighlight">\(P(X)\)</span> sama untuk semua kelas, bisa diabaikan dalam perbandingan.</p>
<div class="math notranslate nohighlight">
\[
P(C_k \mid X) \propto P(C_k) \cdot \prod_{j=1}^{n} P(x_j \mid C_k)
\]</div>
<blockquote>
<div><p>Artinya: <strong>Probabilitas kelas</strong> diberikan fitur <span class="math notranslate nohighlight">\(X = (x_1, x_2, ..., x_n)\)</span> adalah produk dari prior dan semua likelihood.</p>
</div></blockquote>
</section>
<hr class="docutils" />
<section id="langkah-4-pilih-kelas-dengan-probabilitas-posterior-tertinggi">
<h2>🔹 <strong>Langkah 4: Pilih Kelas dengan Probabilitas Posterior Tertinggi</strong><a class="headerlink" href="#langkah-4-pilih-kelas-dengan-probabilitas-posterior-tertinggi" title="Link to this heading">#</a></h2>
<div class="math notranslate nohighlight">
\[
\hat{C} = \arg\max_{C_k} P(C_k) \cdot \prod_{j=1}^{n} P(x_j \mid C_k)
\]</div>
<hr class="docutils" />
</section>
</section>
<section id="ringkasan-singkat">
<h1>🔁 Ringkasan Singkat:<a class="headerlink" href="#ringkasan-singkat" title="Link to this heading">#</a></h1>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Langkah</p></th>
<th class="head"><p>Keterangan</p></th>
<th class="head"><p>Rumus</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1</p></td>
<td><p>Hitung prior tiap kelas</p></td>
<td><p><span class="math notranslate nohighlight">\(P(C_k) = \frac{n_k}{n}\)</span></p></td>
</tr>
<tr class="row-odd"><td><p>2</p></td>
<td><p>Hitung likelihood tiap fitur</p></td>
<td><p><span class="math notranslate nohighlight">\(P(x_j \mid C_k) = \text{Gaussian / kategorikal}\)</span></p></td>
</tr>
<tr class="row-even"><td><p>3</p></td>
<td><p>Hitung posterior</p></td>
<td><p><span class="math notranslate nohighlight">\(P(C_k \mid X) \propto P(C_k) \cdot \prod P(x_j \mid C_k)\)</span></p></td>
</tr>
<tr class="row-odd"><td><p>4</p></td>
<td><p>Prediksi kelas</p></td>
<td><p><span class="math notranslate nohighlight">\(\hat{C} = \arg\max P(C_k \mid X)\)</span></p></td>
</tr>
</tbody>
</table>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.naive_bayes</span><span class="w"> </span><span class="kn">import</span> <span class="n">GaussianNB</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">classification_report</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="c1"># ======== Naive Bayes ========</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">🧪 [Naive Bayes] Mulai Evaluasi Model...</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Train Model</span>
<span class="n">nb_model</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>
<span class="n">nb_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Predict</span>
<span class="n">y_pred_nb</span> <span class="o">=</span> <span class="n">nb_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Evaluation</span>
<span class="n">acc_nb</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_nb</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;📈 Akurasi Naive Bayes: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">acc_nb</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">📋 Classification Report (Naive Bayes):&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_nb</span><span class="p">))</span>

<span class="c1"># Hasil Prediksi</span>
<span class="n">df_nb</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df_nb</span><span class="p">[</span><span class="s2">&quot;True Label&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_test</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df_nb</span><span class="p">[</span><span class="s2">&quot;Predicted Label&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_pred_nb</span>
<span class="n">df_nb</span><span class="p">[</span><span class="s2">&quot;Status&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_nb</span><span class="p">[</span><span class="s2">&quot;True Label&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="n">df_nb</span><span class="p">[</span><span class="s2">&quot;Predicted Label&quot;</span><span class="p">]</span>
<span class="n">df_nb</span><span class="p">[</span><span class="s2">&quot;Status&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_nb</span><span class="p">[</span><span class="s2">&quot;Status&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">({</span><span class="kc">True</span><span class="p">:</span> <span class="s2">&quot;✅ Benar&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">:</span> <span class="s2">&quot;❌ Salah&quot;</span><span class="p">})</span>

<span class="c1"># Output Prediksi</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">✅ Contoh Prediksi Benar (Naive Bayes):&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df_nb</span><span class="p">[</span><span class="n">df_nb</span><span class="p">[</span><span class="s2">&quot;Status&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;✅ Benar&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">head</span><span class="p">()</span><span class="o">.</span><span class="n">to_string</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">❌ Contoh Prediksi Salah (Naive Bayes):&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df_nb</span><span class="p">[</span><span class="n">df_nb</span><span class="p">[</span><span class="s2">&quot;Status&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;❌ Salah&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">head</span><span class="p">()</span><span class="o">.</span><span class="n">to_string</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>🧪 [Naive Bayes] Mulai Evaluasi Model...

📈 Akurasi Naive Bayes: 0.9394

📋 Classification Report (Naive Bayes):
              precision    recall  f1-score   support

           1       0.86      1.00      0.92        12
           2       1.00      0.83      0.91        12
           3       1.00      1.00      1.00         9

    accuracy                           0.94        33
   macro avg       0.95      0.94      0.94        33
weighted avg       0.95      0.94      0.94        33


✅ Contoh Prediksi Benar (Naive Bayes):
 Alcohol  Malicacid  Ash  Alcalinity_of_ash  Magnesium  Total_phenols  Flavanoids  Nonflavanoid_phenols  Proanthocyanins  Color_intensity  Hue  0D280_0D315_of_diluted_wines  Proline  True Label  Predicted Label  Status
   14.06       1.63 2.28               16.0        126           3.00        3.17                  0.24             2.10             5.65 1.09                          3.71      780           1                1 ✅ Benar
   12.72       1.75 2.28               22.5         84           1.38        1.76                  0.48             1.63             3.30 0.88                          2.42      488           2                2 ✅ Benar
   12.64       1.36 2.02               16.8        100           2.02        1.41                  0.53             0.62             5.75 0.98                          1.59      450           2                2 ✅ Benar
   14.02       1.68 2.21               16.0         96           2.65        2.33                  0.26             1.98             4.70 1.04                          3.59     1035           1                1 ✅ Benar
   14.22       3.99 2.51               13.2        128           3.00        3.04                  0.20             2.08             5.10 0.89                          3.53      760           1                1 ✅ Benar

❌ Contoh Prediksi Salah (Naive Bayes):
 Alcohol  Malicacid  Ash  Alcalinity_of_ash  Magnesium  Total_phenols  Flavanoids  Nonflavanoid_phenols  Proanthocyanins  Color_intensity  Hue  0D280_0D315_of_diluted_wines  Proline  True Label  Predicted Label  Status
   13.11       1.01  1.7               15.0         78           2.98        3.18                  0.26             2.28              5.3 1.12                          3.18      502           2                1 ❌ Salah
   12.37       1.07  2.1               18.5         88           3.52        3.75                  0.24             1.95              4.5 1.04                          2.77      660           2                1 ❌ Salah
</pre></div>
</div>
</div>
</div>
</section>
<section id="klasifikasi-dengan-decision-tree">
<h1><strong>Klasifikasi dengan Decision Tree</strong><a class="headerlink" href="#klasifikasi-dengan-decision-tree" title="Link to this heading">#</a></h1>
</section>
<section id="decision-tree">
<h1>🌳 <strong>4. Decision Tree</strong><a class="headerlink" href="#decision-tree" title="Link to this heading">#</a></h1>
<p><strong>Decision Tree</strong> (pohon keputusan) adalah metode klasifikasi yang membagi data secara rekursif berdasarkan fitur yang paling informatif (berdasarkan Gini atau Entropy).</p>
<hr class="docutils" />
<section id="langkah-langkah-decision-tree">
<h2>✅ <strong>Langkah-langkah Decision Tree</strong><a class="headerlink" href="#langkah-langkah-decision-tree" title="Link to this heading">#</a></h2>
<ol class="arabic simple">
<li><p><strong>Hitung impurity (ketidakmurnian)</strong> untuk seluruh dataset</p></li>
<li><p><strong>Evaluasi semua fitur dan semua nilai split</strong></p></li>
<li><p><strong>Pilih fitur dan split dengan impurity terkecil (Information Gain terbesar)</strong></p></li>
<li><p><strong>Buat simpul berdasarkan fitur terbaik</strong></p></li>
<li><p><strong>Ulangi langkah 1–4 secara rekursif pada subset kiri dan kanan</strong></p></li>
<li><p>Berhenti jika:</p>
<ul class="simple">
<li><p>Semua data dalam simpul punya label sama</p></li>
<li><p>Maksimal kedalaman pohon tercapai</p></li>
<li><p>Tidak ada lagi fitur yang bisa digunakan</p></li>
</ul>
</li>
</ol>
<hr class="docutils" />
</section>
</section>
<section id="rumus-rumus-penting">
<h1>🧠 Rumus-Rumus Penting<a class="headerlink" href="#rumus-rumus-penting" title="Link to this heading">#</a></h1>
<hr class="docutils" />
<section id="entropy">
<h2>🔹 1. <strong>Entropy</strong><a class="headerlink" href="#entropy" title="Link to this heading">#</a></h2>
<p>Mengukur ketidakpastian suatu dataset:</p>
<div class="math notranslate nohighlight">
\[
Entropy(S) = -\sum_{i=1}^{C} p_i \log_2 p_i
\]</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(p_i\)</span>: proporsi data dengan label ke-i</p></li>
<li><p>C: jumlah kelas</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="gini-impurity">
<h2>🔹 2. <strong>Gini Impurity</strong><a class="headerlink" href="#gini-impurity" title="Link to this heading">#</a></h2>
<p>Alternatif Entropy (umumnya digunakan pada CART):</p>
<div class="math notranslate nohighlight">
\[
Gini(S) = 1 - \sum_{i=1}^{C} p_i^2
\]</div>
</section>
<hr class="docutils" />
<section id="information-gain-ig">
<h2>🔹 3. <strong>Information Gain (IG)</strong><a class="headerlink" href="#information-gain-ig" title="Link to this heading">#</a></h2>
<p>Selisih impurity sebelum dan sesudah split (dipakai saat pakai entropy):</p>
<div class="math notranslate nohighlight">
\[
IG(S, A) = Entropy(S) - \sum_{v \in Values(A)} \frac{|S_v|}{|S|} \cdot Entropy(S_v)
\]</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(S\)</span>: seluruh data</p></li>
<li><p><span class="math notranslate nohighlight">\(A\)</span>: atribut/faktor yang ingin diuji</p></li>
<li><p><span class="math notranslate nohighlight">\(S_v\)</span>: subset data saat fitur <span class="math notranslate nohighlight">\(A = v\)</span></p></li>
</ul>
<hr class="docutils" />
</section>
</section>
<section id="ringkasan-langkah-recursive-decision-tree">
<h1>🧭 Ringkasan Langkah Recursive Decision Tree<a class="headerlink" href="#ringkasan-langkah-recursive-decision-tree" title="Link to this heading">#</a></h1>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Langkah</p></th>
<th class="head"><p>Penjelasan</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1</p></td>
<td><p>Hitung impurity (Gini atau Entropy) awal pada seluruh dataset</p></td>
</tr>
<tr class="row-odd"><td><p>2</p></td>
<td><p>Cek semua fitur dan nilai-nilainya, hitung impurity setelah split</p></td>
</tr>
<tr class="row-even"><td><p>3</p></td>
<td><p>Hitung gain, pilih fitur dan nilai split terbaik</p></td>
</tr>
<tr class="row-odd"><td><p>4</p></td>
<td><p>Buat node (simpul) berdasarkan fitur terbaik</p></td>
</tr>
<tr class="row-even"><td><p>5</p></td>
<td><p>Bagi data ke cabang kiri dan kanan</p></td>
</tr>
<tr class="row-odd"><td><p>6</p></td>
<td><p>Ulangi proses untuk tiap subset (secara rekursif)</p></td>
</tr>
</tbody>
</table>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.tree</span><span class="w"> </span><span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">classification_report</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="c1"># ======== Decision Tree ========</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">🧪 [Decision Tree] Mulai Evaluasi Model...</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Train Model</span>
<span class="n">dt_model</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">dt_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Predict</span>
<span class="n">y_pred_dt</span> <span class="o">=</span> <span class="n">dt_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Evaluation</span>
<span class="n">acc_dt</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_dt</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;📈 Akurasi Decision Tree: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">acc_dt</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">📋 Classification Report (Decision Tree):&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_dt</span><span class="p">))</span>

<span class="c1"># Hasil Prediksi</span>
<span class="n">df_dt</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df_dt</span><span class="p">[</span><span class="s2">&quot;True Label&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_test</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df_dt</span><span class="p">[</span><span class="s2">&quot;Predicted Label&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_pred_dt</span>
<span class="n">df_dt</span><span class="p">[</span><span class="s2">&quot;Status&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_dt</span><span class="p">[</span><span class="s2">&quot;True Label&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="n">df_dt</span><span class="p">[</span><span class="s2">&quot;Predicted Label&quot;</span><span class="p">]</span>
<span class="n">df_dt</span><span class="p">[</span><span class="s2">&quot;Status&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_dt</span><span class="p">[</span><span class="s2">&quot;Status&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">({</span><span class="kc">True</span><span class="p">:</span> <span class="s2">&quot;✅ Benar&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">:</span> <span class="s2">&quot;❌ Salah&quot;</span><span class="p">})</span>

<span class="c1"># Output Prediksi</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">✅ Contoh Prediksi Benar (Decision Tree):&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df_dt</span><span class="p">[</span><span class="n">df_dt</span><span class="p">[</span><span class="s2">&quot;Status&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;✅ Benar&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">head</span><span class="p">()</span><span class="o">.</span><span class="n">to_string</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">❌ Contoh Prediksi Salah (Decision Tree):&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df_dt</span><span class="p">[</span><span class="n">df_dt</span><span class="p">[</span><span class="s2">&quot;Status&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;❌ Salah&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">head</span><span class="p">()</span><span class="o">.</span><span class="n">to_string</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>🧪 [Decision Tree] Mulai Evaluasi Model...

📈 Akurasi Decision Tree: 0.9394

📋 Classification Report (Decision Tree):
              precision    recall  f1-score   support

           1       1.00      0.92      0.96        12
           2       0.92      0.92      0.92        12
           3       0.90      1.00      0.95         9

    accuracy                           0.94        33
   macro avg       0.94      0.94      0.94        33
weighted avg       0.94      0.94      0.94        33


✅ Contoh Prediksi Benar (Decision Tree):
 Alcohol  Malicacid  Ash  Alcalinity_of_ash  Magnesium  Total_phenols  Flavanoids  Nonflavanoid_phenols  Proanthocyanins  Color_intensity  Hue  0D280_0D315_of_diluted_wines  Proline  True Label  Predicted Label  Status
   14.06       1.63 2.28               16.0        126           3.00        3.17                  0.24             2.10             5.65 1.09                          3.71      780           1                1 ✅ Benar
   12.72       1.75 2.28               22.5         84           1.38        1.76                  0.48             1.63             3.30 0.88                          2.42      488           2                2 ✅ Benar
   14.02       1.68 2.21               16.0         96           2.65        2.33                  0.26             1.98             4.70 1.04                          3.59     1035           1                1 ✅ Benar
   14.22       3.99 2.51               13.2        128           3.00        3.04                  0.20             2.08             5.10 0.89                          3.53      760           1                1 ✅ Benar
   11.66       1.88 1.92               16.0         97           1.61        1.57                  0.34             1.15             3.80 1.23                          2.14      428           2                2 ✅ Benar

❌ Contoh Prediksi Salah (Decision Tree):
 Alcohol  Malicacid  Ash  Alcalinity_of_ash  Magnesium  Total_phenols  Flavanoids  Nonflavanoid_phenols  Proanthocyanins  Color_intensity  Hue  0D280_0D315_of_diluted_wines  Proline  True Label  Predicted Label  Status
   12.64       1.36 2.02               16.8        100           2.02        1.41                  0.53             0.62             5.75 0.98                          1.59      450           2                3 ❌ Salah
   13.24       3.98 2.29               17.5        103           2.64        2.63                  0.32             1.66             4.36 0.82                          3.00      680           1                2 ❌ Salah
</pre></div>
</div>
</div>
</div>
</section>
<section id="evaluasi-model">
<h1><strong>Evaluasi Model</strong><a class="headerlink" href="#evaluasi-model" title="Link to this heading">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">precision_score</span><span class="p">,</span> <span class="n">recall_score</span><span class="p">,</span> <span class="n">f1_score</span><span class="p">,</span> <span class="n">confusion_matrix</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">seaborn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sns</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="k">def</span><span class="w"> </span><span class="nf">evaluasi_lengkap</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">📊 Evaluasi Lengkap untuk: </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Akurasi     : </span><span class="si">{</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Precision   : </span><span class="si">{</span><span class="n">precision_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">,</span><span class="w"> </span><span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Recall      : </span><span class="si">{</span><span class="n">recall_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">,</span><span class="w"> </span><span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;F1-Score    : </span><span class="si">{</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">,</span><span class="w"> </span><span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Confusion Matrix</span>
    <span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s2">&quot;d&quot;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;Blues&quot;</span><span class="p">,</span> <span class="n">cbar</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Confusion Matrix - </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Predicted&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Actual&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<section id="penerapan-ke-knn">
<h2><strong>Penerapan ke KNN</strong><a class="headerlink" href="#penerapan-ke-knn" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">evaluasi_lengkap</span><span class="p">(</span><span class="s2">&quot;K-Nearest Neighbors&quot;</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_knn</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>📊 Evaluasi Lengkap untuk: K-Nearest Neighbors
Akurasi     : 0.7576
Precision   : 0.7732
Recall      : 0.7576
F1-Score    : 0.7351
</pre></div>
</div>
<img alt="_images/4f78cf9759c9d72658f55b09ebbb0a844d605a909866a86b0eb27ef53e266236.png" src="_images/4f78cf9759c9d72658f55b09ebbb0a844d605a909866a86b0eb27ef53e266236.png" />
</div>
</div>
</section>
<section id="penerapan-ke-naive-bayes">
<h2><strong>Penerapan ke Naive Bayes</strong><a class="headerlink" href="#penerapan-ke-naive-bayes" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">evaluasi_lengkap</span><span class="p">(</span><span class="s2">&quot;Naive Bayes&quot;</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_nb</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>📊 Evaluasi Lengkap untuk: Naive Bayes
Akurasi     : 0.9394
Precision   : 0.9481
Recall      : 0.9394
F1-Score    : 0.9390
</pre></div>
</div>
<img alt="_images/6137fd2c7c75b7f8612e5997b1ce38c7df267299c690a1a30da9c87a6de01072.png" src="_images/6137fd2c7c75b7f8612e5997b1ce38c7df267299c690a1a30da9c87a6de01072.png" />
</div>
</div>
</section>
<section id="penerapan-ke-decision-tree">
<h2><strong>Penerapan ke Decision Tree</strong><a class="headerlink" href="#penerapan-ke-decision-tree" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">evaluasi_lengkap</span><span class="p">(</span><span class="s2">&quot;Decision Tree&quot;</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_dt</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>📊 Evaluasi Lengkap untuk: Decision Tree
Akurasi     : 0.9394
Precision   : 0.9424
Recall      : 0.9394
F1-Score    : 0.9395
</pre></div>
</div>
<img alt="_images/0221cc215e1adb23816bcfad129201edf690db3464344a06274bfcd4c8da342b.png" src="_images/0221cc215e1adb23816bcfad129201edf690db3464344a06274bfcd4c8da342b.png" />
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="KBinsDiscretizer.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">KBinsDiscretizer</p>
      </div>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#"><strong>Pendahuluan</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#data-understanding"><strong>Data Understanding</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#integrasi-data"><strong>Integrasi Data</strong></a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mengambil-dan-menampilkan-dataset-wine-quality-dari-uci-dengan-ucimlrepo-dan-pandas">Mengambil dan Menampilkan Dataset Wine Quality dari UCI dengan ucimlrepo dan pandas</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fitur-x-dan-target-y-digabung">Fitur X dan target y digabung</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#penjelasan-setiap-fitur-variabel-dataset-anggur"><strong>Penjelasan Setiap Fitur (Variabel) Dataset Anggur</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#variabel-target-output">Variabel Target (Output):</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#eksplorasi-data"><strong>Eksplorasi Data</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visualisasi-data"><strong>Visualisasi Data</strong></a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#preprocessing-data"><strong>Preprocessing Data</strong></a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rumus-untuk-standardisasi-standardscaler">1. Rumus untuk Standardisasi (StandardScaler)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rumus-untuk-reduksi-dimensi-pca-principal-component-analysis">2. Rumus untuk Reduksi Dimensi (PCA - Principal Component Analysis)</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#deteksi-outlier-menggunakan-local-outlier-factor-lof"><strong>deteksi outlier menggunakan Local Outlier Factor (LOF)</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#menggunakan-local-outlier-factor-lof-untuk-mendeteksi-outlier-pada-data-anggur-dan-ingin-memahami-konsep-konsep-di-baliknya-secara-berurutan-ini-adalah-pilihan-yang-sangat-baik-karena-lof-adalah-metode-yang-kuat-untuk-mendeteksi-outlier-berbasis-kepadatan">menggunakan <strong>Local Outlier Factor (LOF)</strong> untuk mendeteksi <em>outlier</em> pada data anggur, dan ingin memahami konsep-konsep di baliknya secara berurutan. Ini adalah pilihan yang sangat baik karena LOF adalah metode yang kuat untuk mendeteksi <em>outlier</em> berbasis kepadatan.</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#konsep-lof">Konsep LOF</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#k-distance-dan-k-neighbors">1. K-distance dan K-neighbors</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#reachability-distance-rd">2. Reachability Distance (RD)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#local-reachability-density-lrd">3. Local Reachability Density (LRD)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#local-outlier-factor-lof">4. Local Outlier Factor (LOF)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#pengecekan-ulang-apakah-data-masih-memiliki-outlier"><strong>pengecekan ulang apakah data masih memiliki outlier</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#menghapus-outlier-dengan-iqr"><strong>Menghapus Outlier dengan IQR</strong></a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rumus-matematika-deteksi-outlier-dengan-metode-iqr">Rumus Matematika Deteksi Outlier dengan Metode IQR</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#data-splitting"><strong>Data Splitting</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#klasifikasi-dengan-k-nearest-neighbors-knn"><strong>Klasifikasi dengan K-Nearest Neighbors (KNN)</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#tujuan-knn">🧭 <strong>Tujuan KNN:</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#langkah-langkah-knn-manual-dengan-jarak-euclidean">✅ <strong>Langkah-Langkah KNN (Manual dengan Jarak Euclidean)</strong></a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#langkah-1-hitung-jarak-euclidean-antara-data-uji-dan-semua-data-latih"><strong>Langkah 1: Hitung Jarak Euclidean antara data uji dan semua data latih</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#langkah-2-urutkan-data-latih-berdasarkan-jarak-terkecil"><strong>Langkah 2: Urutkan data latih berdasarkan jarak terkecil</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#langkah-3-ambil-k-tetangga-terdekat"><strong>Langkah 3: Ambil k tetangga terdekat</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#langkah-4-lakukan-voting-mayoritas-dari-label-k-tetangga"><strong>Langkah 4: Lakukan voting mayoritas dari label k tetangga</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#langkah-5-prediksi-selesai"><strong>Langkah 5: Prediksi selesai</strong></a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#klasifikasi-dengan-naive-bayes-gaussiannb"><strong>Klasifikasi dengan Naive Bayes (GaussianNB)</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#naive-bayes-classifier">📘 <strong>Naive Bayes Classifier</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#langkah-langkah-rumus-naive-bayes">✅ <strong>Langkah-langkah &amp; Rumus Naive Bayes</strong></a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#langkah-1-hitung-probabilitas-prior-tiap-kelas">🔹 <strong>Langkah 1: Hitung Probabilitas Prior Tiap Kelas</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#langkah-2-hitung-probabilitas-likelihood-untuk-tiap-fitur">🔹 <strong>Langkah 2: Hitung Probabilitas Likelihood untuk Tiap Fitur</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#untuk-data-numerik-gaussian-naive-bayes-digunakan-distribusi-normal">Untuk data numerik (Gaussian Naive Bayes), digunakan distribusi normal:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#untuk-data-kategorikal-multinomial-bernoulli-naive-bayes">Untuk data kategorikal (Multinomial/ Bernoulli Naive Bayes):</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#langkah-3-gunakan-teorema-bayes-untuk-probabilitas-posterior">🔹 <strong>Langkah 3: Gunakan Teorema Bayes untuk Probabilitas Posterior</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#langkah-4-pilih-kelas-dengan-probabilitas-posterior-tertinggi">🔹 <strong>Langkah 4: Pilih Kelas dengan Probabilitas Posterior Tertinggi</strong></a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#ringkasan-singkat">🔁 Ringkasan Singkat:</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#klasifikasi-dengan-decision-tree"><strong>Klasifikasi dengan Decision Tree</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#decision-tree">🌳 <strong>4. Decision Tree</strong></a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#langkah-langkah-decision-tree">✅ <strong>Langkah-langkah Decision Tree</strong></a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#rumus-rumus-penting">🧠 Rumus-Rumus Penting</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#entropy">🔹 1. <strong>Entropy</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gini-impurity">🔹 2. <strong>Gini Impurity</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#information-gain-ig">🔹 3. <strong>Information Gain (IG)</strong></a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#ringkasan-langkah-recursive-decision-tree">🧭 Ringkasan Langkah Recursive Decision Tree</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluasi-model"><strong>Evaluasi Model</strong></a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#penerapan-ke-knn"><strong>Penerapan ke KNN</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#penerapan-ke-naive-bayes"><strong>Penerapan ke Naive Bayes</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#penerapan-ke-decision-tree"><strong>Penerapan ke Decision Tree</strong></a></li>
</ul>
</li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Rohman Maulana
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>